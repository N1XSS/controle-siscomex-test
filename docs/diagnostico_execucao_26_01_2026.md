# RELAT√ìRIO T√âCNICO: Problemas de Rate Limiting e Perda de Dados no Sistema Siscomex

**Data:** 25/01/2026  
**Sistema:** Controle Siscomex - Sincroniza√ß√£o de DUEs  
**Ambiente:** Teste (testes-controle-siscomex-teste)

---

## 1. RESUMO EXECUTIVO

Durante a execu√ß√£o da sincroniza√ß√£o de DUEs, o sistema processou 425 de 500 DUEs antes de atingir o limite de rate limiting da API do Siscomex. Os dados foram coletados com sucesso, mas **n√£o foram salvos no banco de dados** porque o processo foi interrompido antes de concluir todas as 500 DUEs. Al√©m disso, foi identificado um **problema cr√≠tico de race condition** no sistema de rate limiting que permite m√∫ltiplas threads ultrapassarem o limite simultaneamente.

**Impacto:**
- 425 DUEs processadas e perdidas (dados em mem√≥ria n√£o persistidos)
- Taxa de requisi√ß√µes muito acima do limite (25.500 req/h vs 900 req/h configurado)
- Perda de tempo e recursos da API

---

## 2. CRONOLOGIA DOS EVENTOS

### 2.1. Execu√ß√£o da Sincroniza√ß√£o (14:48:36)

**Etapa 1: Novas DUEs**
- 1422 NFs carregadas do SAP
- 1406 v√≠nculos existentes no banco
- 16 NFs sem v√≠nculo identificadas
- 16 NFs consultadas na API do Siscomex
- **Resultado:** 0 novas DUEs encontradas (essas NFs n√£o t√™m DUE no Siscomex)
- **Erro:** `UnboundLocalError: 'dues_erro'` (vari√°vel n√£o inicializada) - **CORRIGIDO**

**Etapa 2: Atualiza√ß√£o de DUEs Existentes (14:49:22)**
- 975 DUEs √≥rf√£s encontradas (v√≠nculo sem dados)
- Limitado a 500 DUEs por execu√ß√£o
- Processamento iniciado com 20 workers paralelos
- Cada DUE faz 1 requisi√ß√£o (apenas atos suspens√£o habilitado)

### 2.2. Processamento e Limite (14:49:23 - 14:49:38)

- **14:49:23:** In√≠cio do processamento paralelo
- **14:49:24:** 25/500 DUEs processadas
- **14:49:25:** 50/500 DUEs processadas
- **14:49:38:** 425/500 DUEs processadas
- **14:49:38:** **Limite de rate limiting atingido (900 req/h)**
- **14:49:38:** M√∫ltiplas threads aguardando 10.4 minutos
- **14:52:** Processo suspenso manualmente

### 2.3. Resultado Final

- **DUEs processadas:** 425/500 (85%)
- **Dados coletados:** 425 DUEs em mem√≥ria (`dados_consolidados`)
- **Dados salvos no banco:** 0 (processo interrompido antes de salvar)
- **Dados perdidos:** 425 DUEs

---

## 3. PROBLEMAS IDENTIFICADOS

### 3.1. PROBLEMA CR√çTICO: Race Condition no Rate Limiter

**Arquivo:** `/app/src/api/siscomex/token.py`  
**Fun√ß√£o:** `_wait_for_safe_limit()`

**C√≥digo Problem√°tico:**
```python
def _wait_for_safe_limit(self) -> None:
    while True:
        with self._request_lock:
            if self._requests_in_window < self._safe_request_limit:
                self._requests_in_window += 1
                return  # ‚Üê PROBLEMA: Retorna antes da requisi√ß√£o HTTP
```

**Problema:**
1. M√∫ltiplas threads verificam `if self._requests_in_window < self._safe_request_limit` **simultaneamente**
2. Todas passam pela verifica√ß√£o antes do incremento
3. Todas incrementam o contador e retornam
4. A requisi√ß√£o HTTP real acontece **DEPOIS** do return
5. Resultado: v√°rias threads fazem requisi√ß√µes mesmo ap√≥s o limite

**Evid√™ncia:**
- Taxa observada: ~425 req/min = **25.500 req/h**
- Limite configurado: 900 req/h
- **28x acima do limite!**

### 3.2. PROBLEMA: Perda de Dados por Interrup√ß√£o

**Arquivo:** `/app/src/sync/update_dues.py`

**Fluxo Atual:**
```python
# 1. Coleta TODAS as DUEs em mem√≥ria
for future in as_completed(...):
    dados_consolidados[tabela].extend(dados)  # Em mem√≥ria

# 2. S√≥ salva DEPOIS de processar todas
if total_atualizadas > 0:
    salvar_resultados_normalizados(dados_consolidados)  # Nunca chegou aqui
```

**Problema:**
- Dados ficam apenas em mem√≥ria durante todo o processamento
- Se o processo for interrompido, todos os dados s√£o perdidos
- N√£o h√° salvamento incremental ou em lotes

### 3.3. PROBLEMA: Processamento Paralelo Excessivo

**Configura√ß√£o Atual:**
- 20 workers paralelos processando simultaneamente
- Cada worker faz requisi√ß√µes independentemente
- Competi√ß√£o pelo mesmo recurso (rate limit)

**Problema:**
- Muitos workers aumentam a chance de race condition
- Dificulta o controle preciso de rate limiting
- Pode causar bloqueios da API

### 3.4. PROBLEMA: TokenBucket Desabilitado

**Arquivo:** `/app/src/api/siscomex/token.py`

**C√≥digo:**
```python
def _build_rate_limiter(self) -> TokenBucket | None:
    """Rate limiter DESABILITADO para maximizar throughput."""
    return None  # Desabilitado
```

**Problema:**
- TokenBucket foi desabilitado porque "serializa threads"
- Mas isso √© exatamente o que precisamos para evitar race condition
- Sistema confia apenas na contagem manual (com race condition)

---

## 4. AN√ÅLISE T√âCNICA

### 4.1. Fluxo de Execu√ß√£o

```
1. ThreadPoolExecutor inicia 20 workers
2. Cada worker chama _wait_for_safe_limit()
3. M√∫ltiplas threads passam pela verifica√ß√£o simultaneamente (race condition)
4. Todas incrementam contador e fazem requisi√ß√µes
5. Contador ultrapassa limite rapidamente
6. Quando detecta limite, todas aguardam 10.4 minutos
7. Processo √© interrompido antes de completar
8. Dados em mem√≥ria s√£o perdidos
```

### 4.2. Comportamento do Rate Limiter

**Quando atinge limite:**
- ‚úÖ Identifica corretamente o limite
- ‚úÖ Calcula tempo at√© pr√≥xima hora cheia
- ‚úÖ Aguarda o tempo necess√°rio
- ‚úÖ Continua ap√≥s a espera (n√£o aborta)
- ‚ùå **MAS:** Race condition permite ultrapassar limite antes

**Tratamento de Erro PUCX-ER1001:**
- ‚úÖ Detecta bloqueio da API
- ‚úÖ Extrai hor√°rio de desbloqueio
- ‚úÖ Coordena todas as threads para aguardar juntas
- ‚úÖ Continua ap√≥s desbloqueio

### 4.3. M√©tricas Observadas

| M√©trica | Valor Observado | Valor Esperado | Status |
|---------|----------------|----------------|--------|
| DUEs processadas | 425/500 | 500/500 | ‚ö†Ô∏è Incompleto |
| Requisi√ß√µes/min | ~425 | ~15 | ‚ùå 28x acima |
| Requisi√ß√µes/hora | ~25.500 | 900 | ‚ùå 28x acima |
| Dados salvos | 0 | 425+ | ‚ùå Perdidos |
| Tempo at√© limite | ~1 minuto | N/A | ‚ùå Muito r√°pido |

---

## 5. SUGEST√ïES DE CORRE√á√ÉO

### 5.1. CORRE√á√ÉO CR√çTICA: Race Condition no Rate Limiter

**Prioridade:** üî¥ URGENTE

**Op√ß√£o A: Usar Sem√°foro (RECOMENDADO)**

**Arquivo:** `/app/src/api/siscomex/token.py`

```python
import threading

class SharedTokenManager:
    def __init__(self):
        # ... c√≥digo existente ...
        # Sem√°foro para limitar requisi√ß√µes simult√¢neas
        self._rate_limit_semaphore = threading.Semaphore(self._safe_request_limit)
        self._semaphore_reset_time = self._current_window_start()
    
    def _wait_for_safe_limit(self) -> None:
        """Usa sem√°foro para garantir limite de requisi√ß√µes."""
        now = datetime.now()
        
        # Resetar sem√°foro a cada hora
        with self._request_lock:
            if now >= self._semaphore_reset_time + timedelta(hours=1):
                # Resetar sem√°foro liberando todos os slots
                current_value = self._rate_limit_semaphore._value
                for _ in range(self._safe_request_limit - current_value):
                    self._rate_limit_semaphore.release()
                self._semaphore_reset_time = self._current_window_start()
        
        # Aguardar slot dispon√≠vel (bloqueia automaticamente se limite atingido)
        self._rate_limit_semaphore.acquire()
        
        # Atualizar contador para logs
        with self._request_lock:
            self._requests_in_window += 1
```

**Vantagens:**
- Thread-safe por design
- Bloqueia automaticamente quando limite atingido
- N√£o permite race condition
- Simples de implementar

**Op√ß√£o B: Corrigir Loop com Sleep Fora do Lock**

```python
def _wait_for_safe_limit(self) -> None:
    """Pausa automaticamente quando atingir limite preventivo."""
    if self._safe_request_limit <= 0:
        return

    while True:
        with self._request_lock:
            now = datetime.now()
            if now >= self._request_window_start + timedelta(hours=1):
                self._request_window_start = self._current_window_start()
                self._requests_in_window = 0

            if self._requests_in_window < self._safe_request_limit:
                self._requests_in_window += 1
                return  # OK para fazer requisi√ß√£o
        
        # Sleep FORA do lock para n√£o bloquear outras threads
        wait_seconds = self._seconds_until_next_hour()
        logger.warning(
            "‚è∏Ô∏è  Limite preventivo SISCOMEX atingido (%s req/h). Aguardando %.1f minutos...",
            self._safe_request_limit,
            wait_seconds / 60.0,
        )
        time.sleep(wait_seconds + 1)
```

**Vantagens:**
- Mant√©m l√≥gica atual
- Corrige race condition
- N√£o bloqueia outras threads desnecessariamente

### 5.2. CORRE√á√ÉO: Salvamento Incremental em Lotes

**Prioridade:** üü° IMPORTANTE

**Arquivo:** `/app/src/sync/update_dues.py`

**Solu√ß√£o: Salvar a cada N DUEs processadas**

```python
# Configura√ß√£o
LOTE_SALVAMENTO = 50  # Salvar a cada 50 DUEs

# No loop de processamento
dados_consolidados = {...}
dados_temporarios = {...}  # Para acumular at√© o lote

for i, future in enumerate(as_completed(future_to_due), 1):
    # ... processar DUE ...
    
    if dados_norm:
        for tabela, dados in dados_norm.items():
            dados_temporarios[tabela].extend(dados)
    
    # Salvar em lotes
    if i % LOTE_SALVAMENTO == 0 or i == len(dues_pendentes):
        logger.info(f"[INFO] Salvando lote de {len(dados_temporarios['due_principal'])} DUEs...")
        salvar_resultados_normalizados(dados_temporarios)
        
        # Consolidar com dados principais
        for tabela, dados in dados_temporarios.items():
            dados_consolidados[tabela].extend(dados)
        
        # Limpar tempor√°rios
        dados_temporarios = {k: [] for k in dados_consolidados.keys()}
```

**Vantagens:**
- Dados salvos progressivamente
- Menor perda em caso de interrup√ß√£o
- Melhor rastreabilidade

### 5.3. CORRE√á√ÉO: Reduzir Workers Paralelos

**Prioridade:** üü° IMPORTANTE

**Arquivo:** `/app/src/sync/update_dues.py`

**Solu√ß√£o: Calcular workers dinamicamente**

```python
from src.core.constants import SISCOMEX_SAFE_REQUEST_LIMIT

# Calcular workers baseado no limite de rate
# Ex: 900 req/h / 100 = 9 workers m√°ximo
# Isso garante que n√£o ultrapasse o limite mesmo com race condition
max_workers_calculado = max(1, int(SISCOMEX_SAFE_REQUEST_LIMIT / 100))
max_workers = min(max_workers, max_workers_calculado)

logger.info(f"[INFO] Workers ajustados: {max_workers} (limite: {SISCOMEX_SAFE_REQUEST_LIMIT} req/h)")
```

**Vantagens:**
- Reduz competi√ß√£o por rate limit
- Facilita controle preciso
- Menor chance de race condition

### 5.4. CORRE√á√ÉO: Reativar TokenBucket (Opcional)

**Prioridade:** üü¢ RECOMENDADO

**Arquivo:** `/app/src/api/siscomex/token.py`

**Solu√ß√£o: Reativar com configura√ß√£o adequada**

```python
def _build_rate_limiter(self) -> TokenBucket | None:
    """Rate limiter para controlar taxa de requisi√ß√µes."""
    from src.core.constants import SISCOMEX_RATE_LIMIT_HOUR, SISCOMEX_RATE_LIMIT_BURST
    
    if SISCOMEX_RATE_LIMIT_HOUR <= 0:
        return None
    
    # 900 req/h = 0.25 req/s (com margem de seguran√ßa)
    rate_per_sec = SISCOMEX_SAFE_REQUEST_LIMIT / 3600.0
    capacity = SISCOMEX_RATE_LIMIT_BURST  # Ex: 20
    
    return TokenBucket(rate_per_sec, capacity)
```

**Uso:**
```python
def request(self, method: str, url: str, **kwargs) -> requests.Response:
    # Rate limiting em camadas
    self._wait_for_safe_limit()  # Controle por hora
    if self._limiter:
        self._limiter.acquire()  # Controle por segundo (TokenBucket)
    
    # Fazer requisi√ß√£o
    resposta = self.session.request(method, url, **kwargs)
    # ...
```

**Vantagens:**
- Camada adicional de prote√ß√£o
- Controle mais fino (por segundo)
- Suporta burst (picos tempor√°rios)

### 5.5. CORRE√á√ÉO: Melhorar Logging e Monitoramento

**Prioridade:** üü¢ RECOMENDADO

**Sugest√µes:**
1. Logar taxa de requisi√ß√µes em tempo real
2. Alertar quando pr√≥ximo do limite (ex: 80%)
3. Logar quando dados s√£o salvos em lotes
4. M√©tricas de performance (req/s, DUEs/s)

```python
# Exemplo de logging melhorado
if self._requests_in_window >= int(self._safe_request_limit * 0.8):
    logger.warning(
        "‚ö†Ô∏è  Aproximando do limite: %d/%d req/h (%.1f%%)",
        self._requests_in_window,
        self._safe_request_limit,
        (self._requests_in_window / self._safe_request_limit) * 100
    )
```

---

## 6. PLANO DE IMPLEMENTA√á√ÉO

### Fase 1: Corre√ß√µes Cr√≠ticas (URGENTE)
1. ‚úÖ Corrigir race condition no `_wait_for_safe_limit()` (Sem√°foro)
2. ‚úÖ Implementar salvamento em lotes
3. ‚úÖ Reduzir workers paralelos dinamicamente

**Prazo:** 1-2 dias  
**Impacto:** Resolve perda de dados e race condition

### Fase 2: Melhorias (IMPORTANTE)
1. Reativar TokenBucket como camada adicional
2. Melhorar logging e monitoramento
3. Adicionar m√©tricas de performance

**Prazo:** 3-5 dias  
**Impacto:** Melhora controle e observabilidade

### Fase 3: Otimiza√ß√µes (RECOMENDADO)
1. Implementar retry inteligente
2. Cache de dados quando poss√≠vel
3. Otimizar queries de banco

**Prazo:** 1-2 semanas  
**Impacto:** Melhora performance geral

---

## 7. TESTES RECOMENDADOS

### Teste 1: Rate Limiting
- Processar 100 DUEs
- Verificar que n√£o ultrapassa 900 req/h
- Confirmar que threads aguardam corretamente

### Teste 2: Salvamento em Lotes
- Processar 200 DUEs
- Interromper no meio (ex: 150 DUEs)
- Verificar que pelo menos 100-150 DUEs foram salvas

### Teste 3: Recupera√ß√£o ap√≥s Limite
- Processar at√© atingir limite
- Aguardar reset da janela
- Verificar que continua processando

### Teste 4: Stress Test
- Processar 1000 DUEs
- Monitorar taxa de requisi√ß√µes
- Verificar que n√£o ultrapassa limite
- Confirmar que todos os dados s√£o salvos

---

## 8. CONCLUS√ïES

### Problemas Identificados
1. ‚úÖ **Race condition cr√≠tica** no rate limiter
2. ‚úÖ **Perda de dados** por falta de salvamento incremental
3. ‚úÖ **Processamento paralelo excessivo** (20 workers)
4. ‚úÖ **TokenBucket desabilitado** (camada de prote√ß√£o removida)

### Impacto
- **Alto:** Perda de dados e viola√ß√£o de rate limiting
- **M√©dio:** Inefici√™ncia e desperd√≠cio de recursos
- **Baixo:** Falta de observabilidade

### Solu√ß√µes Propostas
1. ‚úÖ Sem√°foro para rate limiting thread-safe
2. ‚úÖ Salvamento incremental em lotes
3. ‚úÖ Workers din√¢micos baseados no limite
4. ‚úÖ TokenBucket como camada adicional

### Pr√≥ximos Passos
1. Implementar corre√ß√µes cr√≠ticas (Fase 1)
2. Testar em ambiente de teste
3. Validar que resolve os problemas
4. Deploy em produ√ß√£o com monitoramento

---

## 9. ANEXOS

### 9.1. Logs Relevantes

```
2026-01-25 14:49:38 | INFO | [PROGRESSO] 425/500...
2026-01-25 14:49:38 | WARNING | ‚è∏Ô∏è  Limite preventivo SISCOMEX atingido (900 req/h). Aguardando 10.4 minutos...
```

### 9.2. Configura√ß√µes Atuais

- `SISCOMEX_SAFE_REQUEST_LIMIT`: 900 req/h
- `SISCOMEX_RATE_LIMIT_HOUR`: 1000 req/h
- `DUE_DOWNLOAD_WORKERS`: 20 (padr√£o)
- `MAX_ATUALIZACOES_POR_EXECUCAO`: 500

### 9.3. Arquivos Afetados

- `/app/src/api/siscomex/token.py` (rate limiting)
- `/app/src/sync/update_dues.py` (processamento e salvamento)
- `/app/src/sync/new_dues.py` (vari√°vel n√£o inicializada - corrigido)

---

**Relat√≥rio gerado em:** 25/01/2026  
**Vers√£o:** 1.0  
**Autor:** An√°lise T√©cnica - Sistema Controle Siscomex
