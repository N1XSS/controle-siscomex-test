import json
import os
import threading
import time
import warnings
from typing import Any
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta, timezone

import pandas as pd
import requests
from dotenv import load_dotenv
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

from src.core.constants import DEFAULT_HTTP_TIMEOUT_SEC, ENV_CONFIG_FILE, HTTP_REQUEST_TIMEOUT_SEC
from src.database.manager import db_manager
from src.core.logger import logger
from src.api.siscomex.token import token_manager
warnings.filterwarnings('ignore')

# Flag para usar PostgreSQL ou CSV
USAR_POSTGRESQL = True

# Carregar vari√°veis de ambiente do arquivo .env
load_dotenv(ENV_CONFIG_FILE)

# Configura√ß√µes da API Siscomex
URL_DUE_BASE = "https://portalunico.siscomex.gov.br/due/api/ext/due"

def ler_chaves_nf(arquivo_csv: str = 'dados/nfe-sap.csv') -> list[str]:
    """L√™ as chaves de NF do CSV gerado pelo SAP"""
    try:
        if not os.path.exists(arquivo_csv):
            logger.info(f"‚ùå Arquivo {arquivo_csv} n√£o encontrado")
            logger.info("Execute primeiro o c√≥digo de consulta SAP HANA (sap-nf.py)")
            return []
        
        df = pd.read_csv(arquivo_csv, sep=';', encoding='utf-8-sig')
        
        if 'Chave NF' not in df.columns:
            logger.info("‚ùå Coluna 'Chave NF' n√£o encontrada no CSV")
            return []
        
        # Filtrar apenas chaves v√°lidas (n√£o vazias e n√£o nulas)
        chaves = df['Chave NF'].dropna().astype(str)
        chaves = chaves[chaves.str.len() > 40]  # Chaves NF t√™m 44 d√≠gitos
        chaves = chaves.unique().tolist()
        
        logger.info(f"üìã {len(chaves)} chaves de NF √∫nicas encontradas")
        return chaves
        
    except Exception as e:
        logger.info(f"‚ùå Erro ao ler CSV: {e}")
        return []

def processar_dados_due(
    dados_due: dict[str, Any],
    atos_concessorios: list[dict[str, Any]] | None = None,
    atos_isencao: list[dict[str, Any]] | None = None,
    exigencias_fiscais: list[dict[str, Any]] | None = None,
    debug_mode: bool = False,
) -> dict[str, list[dict[str, Any]]] | None:
    """Processa e normaliza os dados da DUE.

    Args:
        dados_due: Payload completo da DUE.
        atos_concessorios: Lista de atos concessorios de suspensao.
        atos_isencao: Lista de atos concessorios de isencao.
        exigencias_fiscais: Lista de exigencias fiscais.
        debug_mode: Quando True, loga detalhes adicionais.

    Returns:
        Estrutura normalizada por tabela ou None em caso de erro.
    """
    
    # Verifica√ß√£o inicial dos dados
    if not dados_due or not isinstance(dados_due, dict):
        if debug_mode:
            logger.info(f"‚ö†Ô∏è  Dados DUE inv√°lidos ou vazios: {type(dados_due)}")
        return None
    
    numero_due = dados_due.get('numero', '')
    if not numero_due:
        if debug_mode:
            logger.info(f"‚ö†Ô∏è  N√∫mero da DUE n√£o encontrado nos dados")
        return None
    
    # Debug: mostrar estrutura dos dados recebidos
    if debug_mode:
        logger.info(f"üîç Processando DUE {numero_due}:")
        logger.info(f"   ‚Ä¢ Campos principais: {list(dados_due.keys())}")
        logger.info(f"   ‚Ä¢ Eventos hist√≥rico: {len(dados_due.get('eventosDoHistorico', []))}")
        logger.info(f"   ‚Ä¢ Itens: {len(dados_due.get('itens', []))}")
        logger.info(f"   ‚Ä¢ Situa√ß√µes carga: {len(dados_due.get('situacoesDaCarga', []))}")
        logger.info(f"   ‚Ä¢ Solicita√ß√µes: {len(dados_due.get('solicitacoes', []))}")
        logger.info(f"   ‚Ä¢ Declara√ß√£o tribut√°ria: {'declaracaoTributaria' in dados_due}")
        if 'declaracaoTributaria' in dados_due:
            declaracao = dados_due.get('declaracaoTributaria', {})
            logger.info(f"   ‚Ä¢ Compensa√ß√µes: {len(declaracao.get('compensacoes', []))}")
            logger.info(f"   ‚Ä¢ Recolhimentos: {len(declaracao.get('recolhimentos', []))}")
        if atos_concessorios:
            logger.info(f"   ‚Ä¢ Atos concess√≥rios suspens√£o: {len(atos_concessorios) if isinstance(atos_concessorios, list) else 0}")
        if atos_isencao:
            logger.info(f"   ‚Ä¢ Atos concess√≥rios isen√ß√£o: {len(atos_isencao) if isinstance(atos_isencao, list) else 0}")
        if exigencias_fiscais:
            logger.info(f"   ‚Ä¢ Exig√™ncias fiscais: {len(exigencias_fiscais) if isinstance(exigencias_fiscais, list) else 0}")
    
    # Estruturas para armazenar os dados normalizados
    dados_normalizados = {
        'due_principal': [],
        'due_eventos_historico': [],
        'due_itens': [],
        'due_item_enquadramentos': [],
        'due_item_paises_destino': [],
        'due_item_tratamentos_administrativos': [],
        'due_item_tratamentos_administrativos_orgaos': [],
        'due_item_notas_remessa': [],
        'due_item_nota_fiscal_exportacao': [],
        'due_item_notas_complementares': [],
        'due_item_atributos': [],
        'due_item_documentos_importacao': [],
        'due_item_documentos_transformacao': [],
        'due_item_calculo_tributario_tratamentos': [],
        'due_item_calculo_tributario_quadros': [],
        'due_situacoes_carga': [],
        'due_solicitacoes': [],
        'due_declaracao_tributaria_compensacoes': [],
        'due_declaracao_tributaria_recolhimentos': [],
        'due_declaracao_tributaria_contestacoes': [],
        'due_atos_concessorios_suspensao': []
    }
    
    # 1. Dados principais da DUE (1:1)
    due_principal = {
        'numero': numero_due,
        'chaveDeAcesso': dados_due.get('chaveDeAcesso', ''),
        'dataDeRegistro': dados_due.get('dataDeRegistro', ''),
        'bloqueio': dados_due.get('bloqueio', False),
        'canal': dados_due.get('canal', ''),
        'embarqueEmRecintoAlfandegado': dados_due.get('embarqueEmRecintoAlfandegado', False),
        'despachoEmRecintoAlfandegado': dados_due.get('despachoEmRecintoAlfandegado', False),
        'formaDeExportacao': dados_due.get('formaDeExportacao', ''),
        'impedidoDeEmbarque': dados_due.get('impedidoDeEmbarque', False),
        'informacoesComplementares': dados_due.get('informacoesComplementares', ''),
        'ruc': dados_due.get('ruc', ''),
        'situacao': dados_due.get('situacao', ''),
        'situacaoDoTratamentoAdministrativo': dados_due.get('situacaoDoTratamentoAdministrativo', ''),
        'tipo': dados_due.get('tipo', ''),
        'tratamentoPrioritario': dados_due.get('tratamentoPrioritario', False),
        'responsavelPeloACD': dados_due.get('responsavelPeloACD', ''),
        'despachoEmRecintoDomiciliar': dados_due.get('despachoEmRecintoDomiciliar', False),
        'dataDeCriacao': dados_due.get('dataDeCriacao', ''),
        'dataDoCCE': dados_due.get('dataDoCCE', ''),
        'dataDoDesembaraco': dados_due.get('dataDoDesembaraco', ''),
        'dataDoAcd': dados_due.get('dataDoAcd', ''),
        'dataDaAverbacao': dados_due.get('dataDaAverbacao', ''),
        'valorTotalMercadoria': dados_due.get('valorTotalMercadoria', 0),
        'inclusaoNotaFiscal': dados_due.get('inclusaoNotaFiscal', False),
        'exigenciaAtiva': dados_due.get('exigenciaAtiva', False),
        'consorciada': dados_due.get('consorciada', False),
        'dat': dados_due.get('dat', False),
        'oea': dados_due.get('oea', False),
        # Dados do declarante
        'declarante_numeroDoDocumento': dados_due.get('declarante', {}).get('numeroDoDocumento', ''),
        'declarante_tipoDoDocumento': dados_due.get('declarante', {}).get('tipoDoDocumento', ''),
        'declarante_nome': dados_due.get('declarante', {}).get('nome', ''),
        'declarante_estrangeiro': dados_due.get('declarante', {}).get('estrangeiro', False),
        'declarante_nacionalidade_codigo': dados_due.get('declarante', {}).get('nacionalidade', {}).get('codigo', 0),
        'declarante_nacionalidade_nome': dados_due.get('declarante', {}).get('nacionalidade', {}).get('nome', ''),
        'declarante_nacionalidade_nomeResumido': dados_due.get('declarante', {}).get('nacionalidade', {}).get('nomeResumido', ''),
        # Moeda
        'moeda_codigo': dados_due.get('moeda', {}).get('codigo', 0),
        # Pa√≠s importador
        'paisImportador_codigo': dados_due.get('paisImportador', {}).get('codigo', 0),
        # Recintos
        'recintoAduaneiroDeDespacho_codigo': dados_due.get('recintoAduaneiroDeDespacho', {}).get('codigo', ''),
        'recintoAduaneiroDeEmbarque_codigo': dados_due.get('recintoAduaneiroDeEmbarque', {}).get('codigo', ''),
        # Unidades locais
        'unidadeLocalDeDespacho_codigo': dados_due.get('unidadeLocalDeDespacho', {}).get('codigo', ''),
        'unidadeLocalDeEmbarque_codigo': dados_due.get('unidadeLocalDeEmbarque', {}).get('codigo', ''),
        # Declaracao tributaria - divergente
        'declaracaoTributaria_divergente': dados_due.get('declaracaoTributaria', {}).get('divergente', False),
        # Data da ultima atualizacao via API
        'data_ultima_atualizacao': datetime.now(timezone.utc).isoformat(),
    }
    dados_normalizados['due_principal'].append(due_principal)
    
    # 2. Eventos do hist√≥rico
    for evento in dados_due.get('eventosDoHistorico', []):
        evento_row = {
            'numero_due': numero_due,
            'dataEHoraDoEvento': evento.get('dataEHoraDoEvento', ''),
            'evento': evento.get('evento', ''),
            'responsavel': evento.get('responsavel', ''),
            'informacoesAdicionais': evento.get('informacoesAdicionais', ''),
            'detalhes': evento.get('detalhes', ''),
            'motivo': evento.get('motivo', '')
        }
        dados_normalizados['due_eventos_historico'].append(evento_row)
    
    # 3. Itens da DUE
    for item in dados_due.get('itens', []):
        item_id = f"{numero_due}_{item.get('numero', 0)}"
        
        item_row = {
            'id': item_id,
            'numero_due': numero_due,
            'numero': item.get('numero', 0),
            'quantidadeNaUnidadeEstatistica': item.get('quantidadeNaUnidadeEstatistica', 0),
            'pesoLiquidoTotal': item.get('pesoLiquidoTotal', 0),
            'valorDaMercadoriaNaCondicaoDeVenda': item.get('valorDaMercadoriaNaCondicaoDeVenda', 0),
            'valorDaMercadoriaNoLocalDeEmbarque': item.get('valorDaMercadoriaNoLocalDeEmbarque', 0),
            'valorDaMercadoriaNoLocalDeEmbarqueEmReais': item.get('valorDaMercadoriaNoLocalDeEmbarqueEmReais', 0),
            'valorDaMercadoriaNaCondicaoDeVendaEmReais': item.get('valorDaMercadoriaNaCondicaoDeVendaEmReais', 0),
            'dataDeConversao': item.get('dataDeConversao', ''),
            'descricaoDaMercadoria': item.get('descricaoDaMercadoria', ''),
            'unidadeComercializada': item.get('unidadeComercializada', ''),
            'nomeImportador': item.get('nomeImportador', ''),
            'enderecoImportador': item.get('enderecoImportador', ''),
            'valorTotalCalculadoItem': item.get('valorTotalCalculadoItem', 0),
            'quantidadeNaUnidadeComercializada': item.get('quantidadeNaUnidadeComercializada', 0),
            # NCM
            'ncm_codigo': item.get('ncm', {}).get('codigo', ''),
            'ncm_descricao': item.get('ncm', {}).get('descricao', ''),
            'ncm_unidadeMedidaEstatistica': item.get('ncm', {}).get('unidadeMedidaEstatistica', ''),
            # Exportador
            'exportador_numeroDoDocumento': item.get('exportador', {}).get('numeroDoDocumento', ''),
            'exportador_tipoDoDocumento': item.get('exportador', {}).get('tipoDoDocumento', ''),
            'exportador_nome': item.get('exportador', {}).get('nome', ''),
            'exportador_estrangeiro': item.get('exportador', {}).get('estrangeiro', False),
            'exportador_nacionalidade_codigo': item.get('exportador', {}).get('nacionalidade', {}).get('codigo', 0),
            'exportador_nacionalidade_nome': item.get('exportador', {}).get('nacionalidade', {}).get('nome', ''),
            'exportador_nacionalidade_nomeResumido': item.get('exportador', {}).get('nacionalidade', {}).get('nomeResumido', ''),
            # Condi√ß√£o de venda
            'codigoCondicaoVenda': item.get('codigoCondicaoVenda', {}).get('codigo', ''),
            # Exporta√ß√£o tempor√°ria
            'exportacaoTemporaria': item.get('exportacaoTemporaria', {}).get('temporaria', False),
        }
        dados_normalizados['due_itens'].append(item_row)
        
        # 4. Enquadramentos do item
        for enquadramento in item.get('listaDeEnquadramentos', []):
            enq_row = {
                'due_item_id': item_id,
                'numero_due': numero_due,
                'item_numero': item.get('numero', 0),
                'codigo': enquadramento.get('codigo', 0),
                'dataRegistro': enquadramento.get('dataRegistro', ''),
                'descricao': enquadramento.get('descricao', ''),
                'grupo': enquadramento.get('grupo', 0),
                'tipo': enquadramento.get('tipo', 0)
            }
            dados_normalizados['due_item_enquadramentos'].append(enq_row)
        
        # 5. Pa√≠ses de destino do item
        for pais in item.get('listaPaisDestino', []):
            pais_row = {
                'due_item_id': item_id,
                'numero_due': numero_due,
                'item_numero': item.get('numero', 0),
                'codigo_pais': pais.get('codigo', 0)
            }
            dados_normalizados['due_item_paises_destino'].append(pais_row)
        
        # 6. Tratamentos administrativos do item
        for idx, tratamento in enumerate(item.get('tratamentosAdministrativos', [])):
            trat_id = f"{item_id}_{idx}"
            
            trat_row = {
                'id': trat_id,
                'due_item_id': item_id,
                'numero_due': numero_due,
                'item_numero': item.get('numero', 0),
                'mensagem': tratamento.get('mensagem', ''),
                'impeditivoDeEmbarque': tratamento.get('impeditivoDeEmbarque', False),
                'codigoLPCO': tratamento.get('codigoLPCO', ''),
                'situacao': tratamento.get('situacao', '')
            }
            dados_normalizados['due_item_tratamentos_administrativos'].append(trat_row)
            
            # 7. √ìrg√£os dos tratamentos administrativos
            for orgao in tratamento.get('orgaos', []):
                orgao_row = {
                    'tratamento_administrativo_id': trat_id,
                    'due_item_id': item_id,
                    'numero_due': numero_due,
                    'orgao': orgao
                }
                dados_normalizados['due_item_tratamentos_administrativos_orgaos'].append(orgao_row)
        
        # 8. Notas de remessa do item
        for nota_remessa in item.get('itensDaNotaDeRemessa', []):
            nota_row = {
                'due_item_id': item_id,
                'numero_due': numero_due,
                'item_numero': item.get('numero', 0),
                'numeroDoItem': nota_remessa.get('numeroDoItem', 0),
                'chaveDeAcesso': nota_remessa.get('notaFiscal', {}).get('chaveDeAcesso', ''),
                'cfop': nota_remessa.get('cfop', 0),
                'codigoDoProduto': nota_remessa.get('codigoDoProduto', ''),
                'descricao': nota_remessa.get('descricao', ''),
                'quantidadeEstatistica': nota_remessa.get('quantidadeEstatistica', 0),
                'unidadeComercial': nota_remessa.get('unidadeComercial', ''),
                'valorTotalBruto': nota_remessa.get('valorTotalBruto', 0),
                'quantidadeConsumida': nota_remessa.get('quantidadeConsumida', 0),
                'ncm_codigo': nota_remessa.get('ncm', {}).get('codigo', ''),
                'modelo': nota_remessa.get('notaFiscal', {}).get('modelo', ''),
                'serie': nota_remessa.get('notaFiscal', {}).get('serie', 0),
                'numeroDoDocumento': nota_remessa.get('notaFiscal', {}).get('numeroDoDocumento', 0),
                'ufDoEmissor': nota_remessa.get('notaFiscal', {}).get('ufDoEmissor', ''),
                'identificacao_emitente': nota_remessa.get('notaFiscal', {}).get('identificacaoDoEmitente', {}).get('numero', ''),
                'apresentadaParaDespacho': nota_remessa.get('apresentadaParaDespacho', False),
                # Campos adicionais da nota de remessa
                'finalidade': nota_remessa.get('notaFiscal', {}).get('finalidade', ''),
                'quantidadeDeItens': nota_remessa.get('notaFiscal', {}).get('quantidadeDeItens', 0),
                'notaFiscalEletronica': nota_remessa.get('notaFiscal', {}).get('notaFicalEletronica', False),
                'emitente_cnpj': nota_remessa.get('notaFiscal', {}).get('identificacaoDoEmitente', {}).get('cnpj', False),
                'emitente_cpf': nota_remessa.get('notaFiscal', {}).get('identificacaoDoEmitente', {}).get('cpf', False),
                'ncm_descricao': nota_remessa.get('ncm', {}).get('descricao', ''),
                'ncm_unidadeMedidaEstatistica': nota_remessa.get('ncm', {}).get('unidadeMedidaEstatistica', '')
            }
            dados_normalizados['due_item_notas_remessa'].append(nota_row)
    
        # 9. Nota Fiscal de Exporta√ß√£o do item (1:1)
        nf_exportacao = item.get('itemDaNotaFiscalDeExportacao', {})
        if nf_exportacao:
            nf_exp_row = {
                'due_item_id': item_id,
                'numero_due': numero_due,
                'item_numero': item.get('numero', 0),
                'numeroDoItem': nf_exportacao.get('numeroDoItem', 0),
                'chaveDeAcesso': nf_exportacao.get('notaFiscal', {}).get('chaveDeAcesso', ''),
                'modelo': nf_exportacao.get('notaFiscal', {}).get('modelo', ''),
                'serie': nf_exportacao.get('notaFiscal', {}).get('serie', 0),
                'numeroDoDocumento': nf_exportacao.get('notaFiscal', {}).get('numeroDoDocumento', 0),
                'ufDoEmissor': nf_exportacao.get('notaFiscal', {}).get('ufDoEmissor', ''),
                'identificacao_emitente': nf_exportacao.get('notaFiscal', {}).get('identificacaoDoEmitente', {}).get('numero', ''),
                'emitente_cnpj': nf_exportacao.get('notaFiscal', {}).get('identificacaoDoEmitente', {}).get('cnpj', False),
                'emitente_cpf': nf_exportacao.get('notaFiscal', {}).get('identificacaoDoEmitente', {}).get('cpf', False),
                'finalidade': nf_exportacao.get('notaFiscal', {}).get('finalidade', ''),
                'quantidadeDeItens': nf_exportacao.get('notaFiscal', {}).get('quantidadeDeItens', 0),
                'notaFiscalEletronica': nf_exportacao.get('notaFiscal', {}).get('notaFicalEletronica', False),
                'cfop': nf_exportacao.get('cfop', 0),
                'codigoDoProduto': nf_exportacao.get('codigoDoProduto', ''),
                'descricao': nf_exportacao.get('descricao', ''),
                'quantidadeEstatistica': nf_exportacao.get('quantidadeEstatistica', 0),
                'unidadeComercial': nf_exportacao.get('unidadeComercial', ''),
                'valorTotalCalculado': nf_exportacao.get('valorTotalCalculado', 0),
                'ncm_codigo': nf_exportacao.get('ncm', {}).get('codigo', ''),
                'ncm_descricao': nf_exportacao.get('ncm', {}).get('descricao', ''),
                'ncm_unidadeMedidaEstatistica': nf_exportacao.get('ncm', {}).get('unidadeMedidaEstatistica', ''),
                'apresentadaParaDespacho': nf_exportacao.get('apresentadaParaDespacho', False)
            }
            dados_normalizados['due_item_nota_fiscal_exportacao'].append(nf_exp_row)
        
        # 10. Notas Complementares do item
        for idx_nc, nota_compl in enumerate(item.get('itensDeNotaComplementar', [])):
            nc_row = {
                'due_item_id': item_id,
                'numero_due': numero_due,
                'item_numero': item.get('numero', 0),
                'indice': idx_nc,
                'numeroDoItem': nota_compl.get('numeroDoItem', 0),
                'chaveDeAcesso': nota_compl.get('notaFiscal', {}).get('chaveDeAcesso', ''),
                'modelo': nota_compl.get('notaFiscal', {}).get('modelo', ''),
                'serie': nota_compl.get('notaFiscal', {}).get('serie', 0),
                'numeroDoDocumento': nota_compl.get('notaFiscal', {}).get('numeroDoDocumento', 0),
                'ufDoEmissor': nota_compl.get('notaFiscal', {}).get('ufDoEmissor', ''),
                'identificacao_emitente': nota_compl.get('notaFiscal', {}).get('identificacaoDoEmitente', {}).get('numero', ''),
                'cfop': nota_compl.get('cfop', 0),
                'codigoDoProduto': nota_compl.get('codigoDoProduto', ''),
                'descricao': nota_compl.get('descricao', ''),
                'quantidadeEstatistica': nota_compl.get('quantidadeEstatistica', 0),
                'unidadeComercial': nota_compl.get('unidadeComercial', ''),
                'valorTotalBruto': nota_compl.get('valorTotalBruto', 0),
                'ncm_codigo': nota_compl.get('ncm', {}).get('codigo', '')
            }
            dados_normalizados['due_item_notas_complementares'].append(nc_row)
        
        # 11. Atributos do item
        for idx_atr, atributo in enumerate(item.get('atributos', [])):
            atr_row = {
                'due_item_id': item_id,
                'numero_due': numero_due,
                'item_numero': item.get('numero', 0),
                'indice': idx_atr,
                'codigo': atributo.get('codigo', ''),
                'valor': atributo.get('valor', ''),
                'descricao': atributo.get('descricao', '')
            }
            dados_normalizados['due_item_atributos'].append(atr_row)
        
        # 12. Documentos de Importa√ß√£o do item
        for idx_di, doc_imp in enumerate(item.get('documentosImportacao', [])):
            di_row = {
                'due_item_id': item_id,
                'numero_due': numero_due,
                'item_numero': item.get('numero', 0),
                'indice': idx_di,
                'tipo': doc_imp.get('tipo', ''),
                'numero': doc_imp.get('numero', ''),
                'dataRegistro': doc_imp.get('dataRegistro', ''),
                'itemDocumento': doc_imp.get('itemDocumento', 0),
                'quantidadeUtilizada': doc_imp.get('quantidadeUtilizada', 0)
            }
            dados_normalizados['due_item_documentos_importacao'].append(di_row)
        
        # 13. Documentos de Transforma√ß√£o do item
        for idx_dt, doc_transf in enumerate(item.get('documentosDeTransformacao', [])):
            dt_row = {
                'due_item_id': item_id,
                'numero_due': numero_due,
                'item_numero': item.get('numero', 0),
                'indice': idx_dt,
                'tipo': doc_transf.get('tipo', ''),
                'numero': doc_transf.get('numero', ''),
                'dataRegistro': doc_transf.get('dataRegistro', '')
            }
            dados_normalizados['due_item_documentos_transformacao'].append(dt_row)
        
        # 14. C√°lculo Tribut√°rio - Tratamentos
        calculo_tributario = item.get('calculoTributario', {})
        for idx_tt, trat_trib in enumerate(calculo_tributario.get('tratamentosTributarios', [])):
            tt_row = {
                'due_item_id': item_id,
                'numero_due': numero_due,
                'item_numero': item.get('numero', 0),
                'indice': idx_tt,
                'codigo': trat_trib.get('codigo', ''),
                'descricao': trat_trib.get('descricao', ''),
                'tipo': trat_trib.get('tipo', ''),
                'tributo': trat_trib.get('tributo', '')
            }
            dados_normalizados['due_item_calculo_tributario_tratamentos'].append(tt_row)
        
        # 15. C√°lculo Tribut√°rio - Quadros de C√°lculos
        for idx_qc, quadro in enumerate(calculo_tributario.get('quadroDeCalculos', [])):
            qc_row = {
                'due_item_id': item_id,
                'numero_due': numero_due,
                'item_numero': item.get('numero', 0),
                'indice': idx_qc,
                'tributo': quadro.get('tributo', ''),
                'baseDeCalculo': quadro.get('baseDeCalculo', 0),
                'aliquota': quadro.get('aliquota', 0),
                'valorDevido': quadro.get('valorDevido', 0),
                'valorRecolhido': quadro.get('valorRecolhido', 0),
                'valorCompensado': quadro.get('valorCompensado', 0)
            }
            dados_normalizados['due_item_calculo_tributario_quadros'].append(qc_row)
    
    # 16. Situa√ß√µes da carga
    for situacao in dados_due.get('situacoesDaCarga', []):
        sit_row = {
            'numero_due': numero_due,
            'codigo': situacao.get('codigo', 0),
            'descricao': situacao.get('descricao', ''),
            'cargaOperada': situacao.get('cargaOperada', False)
        }
        dados_normalizados['due_situacoes_carga'].append(sit_row)
    
    # 17. Solicita√ß√µes
    for solicitacao in dados_due.get('solicitacoes', []):
        sol_row = {
            'numero_due': numero_due,
            'tipoSolicitacao': solicitacao.get('tipoSolicitacao', ''),
            'dataDaSolicitacao': solicitacao.get('dataDaSolicitacao', ''),
            'usuarioResponsavel': solicitacao.get('usuarioResponsavel', ''),
            'codigoDoStatusDaSolicitacao': solicitacao.get('codigoDoStatusDaSolicitacao', 0),
            'statusDaSolicitacao': solicitacao.get('statusDaSolicitacao', ''),
            'dataDeApreciacao': solicitacao.get('dataDeApreciacao', ''),
            'motivo': solicitacao.get('motivo', '')
        }
        dados_normalizados['due_solicitacoes'].append(sol_row)
    
    # 18. Compensa√ß√µes da declara√ß√£o tribut√°ria
    declaracao_tributaria = dados_due.get('declaracaoTributaria', {})
    if debug_mode:
        logger.info(f"   üîç Processando declara√ß√£o tribut√°ria:")
        logger.info(f"      ‚Ä¢ Compensa√ß√µes: {len(declaracao_tributaria.get('compensacoes', []))}")
        logger.info(f"      ‚Ä¢ Recolhimentos: {len(declaracao_tributaria.get('recolhimentos', []))}")
    
    for compensacao in declaracao_tributaria.get('compensacoes', []):
        comp_row = {
            'numero_due': numero_due,
            'dataDoRegistro': compensacao.get('dataDoRegistro', ''),
            'numeroDaDeclaracao': compensacao.get('numeroDaDeclaracao', ''),
            'valorCompensado': compensacao.get('valorCompensado', 0)
        }
        dados_normalizados['due_declaracao_tributaria_compensacoes'].append(comp_row)
        if debug_mode:
            logger.info(f"      ‚úÖ Compensa√ß√£o adicionada: {compensacao.get('numeroDaDeclaracao', 'N/A')}")
    
    # 19. Recolhimentos da declara√ß√£o tribut√°ria
    for recolhimento in declaracao_tributaria.get('recolhimentos', []):
        rec_row = {
            'numero_due': numero_due,
            'dataDoPagamento': recolhimento.get('dataDoPagamento', ''),
            'dataDoRegistro': recolhimento.get('dataDoRegistro', ''),
            'valorDaMulta': recolhimento.get('valorDaMulta', 0),
            'valorDoImpostoRecolhido': recolhimento.get('valorDoImpostoRecolhido', 0),
            'valorDoJurosMora': recolhimento.get('valorDoJurosMora', 0)
        }
        dados_normalizados['due_declaracao_tributaria_recolhimentos'].append(rec_row)
        if debug_mode:
            logger.info(f"      ‚úÖ Recolhimento adicionado: {recolhimento.get('valorDoImpostoRecolhido', 0)}")
    
    # 20. Contesta√ß√µes da declara√ß√£o tribut√°ria
    for idx_cont, contestacao in enumerate(declaracao_tributaria.get('contestacoes', [])):
        cont_row = {
            'numero_due': numero_due,
            'indice': idx_cont,
            'dataDoRegistro': contestacao.get('dataDoRegistro', ''),
            'motivo': contestacao.get('motivo', ''),
            'status': contestacao.get('status', ''),
            'dataDeApreciacao': contestacao.get('dataDeApreciacao', ''),
            'observacao': contestacao.get('observacao', '')
        }
        dados_normalizados['due_declaracao_tributaria_contestacoes'].append(cont_row)
        if debug_mode:
            logger.info(f"      ‚úÖ Contesta√ß√£o adicionada: {contestacao.get('motivo', 'N/A')}")
    
    # 21. Atos Concess√≥rios de Suspens√£o (Drawback)
    if atos_concessorios and isinstance(atos_concessorios, list):
        if debug_mode:
            logger.info(f"   üîç Processando atos concess√≥rios de suspens√£o: {len(atos_concessorios)} registros")
        
        for idx, ato in enumerate(atos_concessorios):
            ato_row = {
                'numero_due': numero_due,
                'ato_numero': ato.get('numero', ''),
                'tipo_codigo': ato.get('tipo', {}).get('codigo', 0),
                'tipo_descricao': ato.get('tipo', {}).get('descricao', ''),
                'item_numero': ato.get('item', {}).get('numero', ''),
                'item_ncm': ato.get('item', {}).get('ncm', ''),
                'beneficiario_cnpj': ato.get('beneficiario', {}).get('cnpj', ''),
                'quantidadeExportada': ato.get('quantidadeExportada', 0),
                'valorComCoberturaCambial': ato.get('valorComCoberturaCambial', 0),
                'valorSemCoberturaCambial': ato.get('valorSemCoberturaCambial', 0),
                'itemDeDUE_numero': ato.get('itemDeDUE', {}).get('numero', ''),
            }
            dados_normalizados['due_atos_concessorios_suspensao'].append(ato_row)
            if debug_mode:
                logger.info(f"      ‚úÖ Ato concess√≥rio suspens√£o adicionado: {ato.get('numero', 'N/A')}")
    elif debug_mode:
        logger.info(f"   ‚ö†Ô∏è  Nenhum ato concess√≥rio de suspens√£o encontrado")
    
    # 22. Atos Concess√≥rios de Isen√ß√£o (Drawback)
    if atos_isencao and isinstance(atos_isencao, list):
        if debug_mode:
            logger.info(f"   üîç Processando atos concess√≥rios de isen√ß√£o: {len(atos_isencao)} registros")
        
        for idx, ato in enumerate(atos_isencao):
            ato_row = {
                'numero_due': numero_due,
                'ato_numero': ato.get('numero', ''),
                'tipo_codigo': ato.get('tipo', {}).get('codigo', 0),
                'tipo_descricao': ato.get('tipo', {}).get('descricao', ''),
                'item_numero': ato.get('item', {}).get('numero', ''),
                'item_ncm': ato.get('item', {}).get('ncm', ''),
                'beneficiario_cnpj': ato.get('beneficiario', {}).get('cnpj', ''),
                'quantidadeExportada': ato.get('quantidadeExportada', 0),
                'valorComCoberturaCambial': ato.get('valorComCoberturaCambial', 0),
                'valorSemCoberturaCambial': ato.get('valorSemCoberturaCambial', 0),
                'itemDeDUE_numero': ato.get('itemDeDUE', {}).get('numero', ''),
            }
            dados_normalizados['due_atos_concessorios_isencao'].append(ato_row)
            if debug_mode:
                logger.info(f"      ‚úÖ Ato concess√≥rio isen√ß√£o adicionado: {ato.get('numero', 'N/A')}")
    elif debug_mode:
        logger.info(f"   ‚ö†Ô∏è  Nenhum ato concess√≥rio de isen√ß√£o encontrado")
    
    # 23. Exig√™ncias Fiscais
    if exigencias_fiscais and isinstance(exigencias_fiscais, list):
        if debug_mode:
            logger.info(f"   üîç Processando exig√™ncias fiscais: {len(exigencias_fiscais)} registros")
        
        for idx, exigencia in enumerate(exigencias_fiscais):
            exigencia_row = {
                'numero_due': numero_due,
                'numero_exigencia': exigencia.get('numero', '') or exigencia.get('numeroExigencia', ''),
                'tipo_exigencia': exigencia.get('tipo', '') or exigencia.get('tipoExigencia', ''),
                'data_criacao': exigencia.get('dataCriacao', '') or exigencia.get('data_criacao', ''),
                'data_limite': exigencia.get('dataLimite', '') or exigencia.get('data_limite', ''),
                'status': exigencia.get('status', ''),
                'orgao_responsavel': exigencia.get('orgaoResponsavel', '') or exigencia.get('orgao_responsavel', ''),
                'descricao': exigencia.get('descricao', ''),
                'valor_exigido': exigencia.get('valorExigido', 0) or exigencia.get('valor_exigido', 0),
                'valor_pago': exigencia.get('valorPago', 0) or exigencia.get('valor_pago', 0),
                'observacoes': exigencia.get('observacoes', '') or exigencia.get('observacao', ''),
            }
            dados_normalizados['due_exigencias_fiscais'].append(exigencia_row)
            if debug_mode:
                logger.info(f"      ‚úÖ Exig√™ncia fiscal adicionada: {exigencia.get('numero', 'N/A')}")
    elif debug_mode:
        logger.info(f"   ‚ö†Ô∏è  Nenhuma exig√™ncia fiscal encontrada")
    
    return dados_normalizados

def consultar_due_completa(numero_due: str, debug_mode: bool = False) -> dict[str, Any] | None:
    """Consulta os dados completos de uma DUE espec√≠fica"""
    try:
        # Token j√° deve estar v√°lido - n√£o verificar aqui para evitar autentica√ß√µes desnecess√°rias
        # A verifica√ß√£o e renova√ß√£o √© feita apenas centralmente
        
        # URLs alternativas para tentar
        urls_alternativas = [
            f"{URL_DUE_BASE}/numero-da-due/{numero_due}",  # URL correta
            f"{URL_DUE_BASE}/{numero_due}",  # URL alternativa
            f"{URL_DUE_BASE}/detalhes/{numero_due}",  # URL com detalhes
        ]
        
        for i, url_detalhes in enumerate(urls_alternativas):
            try:
                if debug_mode:
                    logger.info(f"üîç Tentativa {i + 1}: {url_detalhes}")
                
                response = token_manager.request("GET", url_detalhes, headers=token_manager.obter_headers(), timeout=DEFAULT_HTTP_TIMEOUT_SEC)
                
                if response.status_code == 401:
                    if debug_mode:
                        logger.info(f"üîë Token expirado ao consultar DUE completa: {numero_due}")
                    return {"error": "token_expirado", "numero_due": numero_due}
                
                if response.status_code == 200:
                    dados_completos = response.json()
                    
                    # Debug: verificar estrutura dos dados retornados
                    if dados_completos:
                        if debug_mode:
                            logger.info(f"‚úÖ Dados completos obtidos para DUE {numero_due} (URL {i + 1})")
                            logger.info(f"   ‚Ä¢ Tipo: {type(dados_completos)}")
                            if isinstance(dados_completos, dict):
                                logger.info(f"   ‚Ä¢ Campos: {list(dados_completos.keys())}")
                                logger.info(f"   ‚Ä¢ Tem itens: {'itens' in dados_completos}")
                                logger.info(f"   ‚Ä¢ Tem eventos: {'eventosDoHistorico' in dados_completos}")
                        return dados_completos
                    else:
                        if debug_mode:
                            logger.info(f"‚ö†Ô∏è  Dados completos vazios para DUE {numero_due} (URL {i + 1})")
                else:
                    if debug_mode:
                        logger.info(f"‚ùå Status {response.status_code} para URL {i + 1}")
                        
            except requests.exceptions.HTTPError as e:
                if debug_mode:
                    logger.info(f"‚ùå Erro HTTP {e.response.status_code} para URL {i + 1}")
                continue
            except Exception as e:
                if debug_mode:
                    logger.info(f"‚ùå Erro para URL {i + 1}: {str(e)[:50]}")
                continue
        
        # Se todas as URLs falharam
        if debug_mode:
            logger.info(f"‚ùå Todas as URLs falharam para DUE {numero_due}")
        return None
        
    except Exception as e:
        if debug_mode:
            logger.info(f"‚ùå Erro inesperado ao consultar DUE {numero_due}: {str(e)}")
        return None

def consultar_due_por_nf(chave_nf: str, debug_mode: bool = False) -> dict[str, Any] | None:
    """
    Consulta DU-E pela chave da NF e obt√©m dados completos
    
    OTIMIZA√á√ïES IMPLEMENTADAS:
    ‚Ä¢ Removidas verifica√ß√µes desnecess√°rias de token_valido() 
    ‚Ä¢ Token gerenciado centralmente com cache persistente
    ‚Ä¢ Evita terceira consulta quando dados da segunda s√£o suficientes
    ‚Ä¢ Reduz de 3 para 2 requisi√ß√µes HTTP na maioria dos casos (33% menos calls)
    """
    try:
        
        # Token j√° deve estar v√°lido - n√£o verificar aqui para evitar autentica√ß√µes desnecess√°rias
        # A verifica√ß√£o e renova√ß√£o √© feita apenas centralmente
        
        # Primeira consulta: obter link da DU-E
        url_primeira = f"{URL_DUE_BASE}?nota-fiscal={chave_nf}"
        
        response1 = token_manager.request("GET", url_primeira, headers=token_manager.obter_headers(), timeout=DEFAULT_HTTP_TIMEOUT_SEC)
        
        if response1.status_code == 401:
            if debug_mode:
                logger.info(f"üîë Token expirado na primeira consulta")
            return {"error": "token_expirado", "chave": chave_nf}
        
        if response1.status_code == 422:
            if debug_mode:
                logger.info(f"‚ö†Ô∏è  Erro 422 - Poss√≠vel rate limiting")
            return None
        
        response1.raise_for_status()
        dados1 = response1.json()
        
        if debug_mode:
            logger.info(f"   Response type: {type(dados1)}")
            logger.info(f"   Response length: {len(dados1) if isinstance(dados1, list) else 'Not a list'}")
        
        if not dados1 or len(dados1) == 0:
            if debug_mode:
                logger.info(f"‚ö†Ô∏è  Primeira consulta retornou dados vazios")
            return None  # Sem DU-E encontrada
        
        # Extrair dados da primeira resposta
        primeiro_item = dados1[0]
        numero_due = primeiro_item.get('rel', '')
        href_due = primeiro_item.get('href', '')
        
        if debug_mode:
            logger.info(f"   N√∫mero DUE: {numero_due}")
            logger.info(f"   HREF DUE: {href_due}")
        
        if not href_due:
            if debug_mode:
                logger.info(f"‚ö†Ô∏è  HREF n√£o encontrado no primeiro item")
            return None  # Link n√£o encontrado
        
        # Segunda consulta: obter detalhes b√°sicos da DU-E
        response2 = token_manager.request("GET", href_due, headers=token_manager.obter_headers(), timeout=DEFAULT_HTTP_TIMEOUT_SEC)
        
        if response2.status_code == 401:
            return {"error": "token_expirado", "chave": chave_nf}
        
        response2.raise_for_status()
        dados2 = response2.json()
        
        # Verificar se j√° temos dados suficientes na segunda consulta
        if debug_mode:
            logger.info(f"üìã Dados da segunda consulta:")
            logger.info(f"   ‚Ä¢ Campos: {list(dados2.keys()) if isinstance(dados2, dict) else 'N√£o √© dict'}")
            logger.info(f"   ‚Ä¢ Tem itens: {'itens' in dados2 if isinstance(dados2, dict) else 'N/A'}")
            logger.info(f"   ‚Ä¢ Tem eventos: {'eventosDoHistorico' in dados2 if isinstance(dados2, dict) else 'N/A'}")
            if isinstance(dados2, dict) and 'itens' in dados2:
                logger.info(f"   ‚Ä¢ Quantidade de itens: {len(dados2['itens'])}")
        
        # OTIMIZA√á√ÉO: Usar dados da segunda consulta como completos - evitar terceira consulta
        dados_completos = dados2
        
        # Consultar atos concess√≥rios de suspens√£o se dispon√≠vel
        # OTIMIZA√á√ÉO: Esta consulta adicional √© mantida pois √© espec√≠fica para drawback
        atos_concessorios = None
        link_atos_suspensao = dados_completos.get('atosConcessoriosSuspensao', {})
        if isinstance(link_atos_suspensao, dict) and link_atos_suspensao.get('href'):
            url_atos = link_atos_suspensao['href']
            if debug_mode:
                logger.info(f"üîç Link para atos concess√≥rios encontrado: {url_atos}")
            
            try:
                atos_response = token_manager.request("GET", url_atos, headers=token_manager.obter_headers(), timeout=DEFAULT_HTTP_TIMEOUT_SEC)
                if atos_response.status_code == 200:
                    atos_concessorios = atos_response.json()
                    if debug_mode and atos_concessorios and isinstance(atos_concessorios, list):
                        logger.info(f"‚úÖ {len(atos_concessorios)} atos concess√≥rios obtidos")
            except Exception as e:
                if debug_mode:
                    logger.info(f"‚ö†Ô∏è  Erro ao consultar atos concess√≥rios: {e}")
        elif debug_mode:
            logger.info(f"‚ö†Ô∏è  Nenhum link para atos concess√≥rios de suspens√£o encontrado")
        
        # OTIMIZA√á√ÉO: Reduzir terceiras consultas desnecess√°rias
        # A segunda consulta j√° cont√©m todos os dados necess√°rios na maioria dos casos
        # S√≥ fazer terceira consulta em casos MUITO espec√≠ficos de dados incompletos
        
        consulta_adicional_necessaria = False
        if not dados_completos or not isinstance(dados_completos, dict):
            consulta_adicional_necessaria = True
            motivo = "dados_completos inv√°lidos"
        elif len(dados_completos.get('itens', [])) == 0 and dados_completos.get('tipo', '') != 'SIMPLIFICADA':
            # S√≥ consultar novamente se n√£o tem itens E n√£o √© DUE simplificada
            consulta_adicional_necessaria = True
            motivo = "sem itens em DUE n√£o-simplificada"
        
        if consulta_adicional_necessaria:
            if debug_mode:
                logger.info(f"üîÑ Terceira consulta necess√°ria: {motivo}")
            
            try:
                dados_terceira_consulta = consultar_due_completa(numero_due, debug_mode)
                
                if dados_terceira_consulta and isinstance(dados_terceira_consulta, dict):
                    if debug_mode:
                        logger.info(f"‚úÖ Dados da terceira consulta obtidos com sucesso")
                    dados_completos = dados_terceira_consulta
                elif debug_mode:
                    logger.info(f"‚ö†Ô∏è  Terceira consulta falhou - mantendo dados da segunda")
            except Exception as e:
                if debug_mode:
                    logger.info(f"‚ö†Ô∏è  Erro na terceira consulta: {e}")
        elif debug_mode:
            logger.info(f"‚úÖ Segunda consulta suficiente - POUPANDO uma requisi√ß√£o HTTP!")
        
        # Resultado b√°sico para CSV principal (usando dados_completos ao inv√©s de dados2)
        resultado_basico = {
            'Chave NF': chave_nf,
            'DU-E': numero_due,
            'canal': dados_completos.get('canal', ''),
            'chaveDeAcesso': dados_completos.get('chaveDeAcesso', ''),
            'situacao': dados_completos.get('situacao', ''),
            'valorTotalMercadoria': dados_completos.get('valorTotalMercadoria', 0)
        }
        
        # Processar dados completos para normaliza√ß√£o
        if dados_completos and isinstance(dados_completos, dict):
            if debug_mode:
                qtd_itens = len(dados_completos.get('itens', []))
                qtd_eventos = len(dados_completos.get('eventosDoHistorico', []))
                logger.info(f"üìä Processando dados completos - DUE: {numero_due} ({qtd_itens} itens, {qtd_eventos} eventos)")
            
            dados_normalizados = processar_dados_due(dados_completos, atos_concessorios, debug_mode)
            if dados_normalizados:
                resultado_basico['dados_completos'] = dados_normalizados
                if debug_mode:
                    total_registros = sum(len(dados) for dados in dados_normalizados.values())
                    logger.info(f"‚úÖ Dados normalizados: {total_registros} registros totais para DUE: {numero_due}")
            else:
                if debug_mode:
                    logger.info(f"‚ö†Ô∏è  Falha ao processar dados normalizados para DUE: {numero_due}")
        else:
            if debug_mode:
                logger.info(f"‚ö†Ô∏è  Dados completos inv√°lidos ou ausentes para DUE: {numero_due}")
        
        return resultado_basico
        
    except requests.exceptions.Timeout:
        return None  # Timeout silencioso para n√£o poluir logs
    except requests.exceptions.HTTPError as e:
        if e.response.status_code == 404:
            return None  # DU-E n√£o encontrada
        else:
            return None  # Outros erros HTTP
    except Exception:
        return None  # Erro gen√©rico

def consultar_due_por_numero(
    chave_nf: str,
    numero_due: str,
    debug_mode: bool = False,
) -> dict[str, Any] | None:
    """
    Consulta DU-E diretamente pelo n√∫mero quando j√° conhecemos a DUE
    
    OTIMIZA√á√ÉO: Pula a primeira consulta (/due/api/ext/due?nota-fiscal=)
    e vai direto para a segunda (/due/api/ext/due/numero-da-due/)
    """
    try:
        if debug_mode:
            logger.info(f"üöÄ [OTIMIZA√á√ÉO] Consultando DUE {numero_due} diretamente (pulando primeira consulta)")
        
        # Ir direto para a segunda consulta - dados completos da DUE
        url_due = f"{URL_DUE_BASE}/numero-da-due/{numero_due}"
        response = token_manager.request("GET", url_due, headers=token_manager.obter_headers(), timeout=DEFAULT_HTTP_TIMEOUT_SEC)
        
        if response.status_code == 401:
            return {"error": "token_expirado", "chave": chave_nf}
        
        if response.status_code == 422:
            if debug_mode:
                logger.info(f"‚ö†Ô∏è  Rate limiting (422) na consulta direta da DUE {numero_due}")
            return None
        
        response.raise_for_status()
        dados_due = response.json()
        
        if not dados_due or not isinstance(dados_due, dict):
            if debug_mode:
                logger.info(f"‚ö†Ô∏è  Dados da DUE {numero_due} inv√°lidos ou vazios")
            return None
        
        # Verificar se temos dados suficientes
        if debug_mode:
            logger.info(f"üìã Dados da consulta direta:")
            logger.info(f"   ‚Ä¢ Campos: {list(dados_due.keys()) if isinstance(dados_due, dict) else 'N√£o √© dict'}")
            logger.info(f"   ‚Ä¢ Tem itens: {'itens' in dados_due if isinstance(dados_due, dict) else 'N/A'}")
            logger.info(f"   ‚Ä¢ Tem eventos: {'eventosDoHistorico' in dados_due if isinstance(dados_due, dict) else 'N/A'}")
            if isinstance(dados_due, dict) and 'itens' in dados_due:
                logger.info(f"   ‚Ä¢ Quantidade de itens: {len(dados_due['itens'])}")
        
        # Consultar atos concess√≥rios de suspens√£o se dispon√≠vel
        atos_concessorios = None
        if numero_due:
            link_atos_suspensao = f"{URL_DUE_BASE}/{numero_due}/drawback/suspensao/atos-concessorios"
            try:
                if debug_mode:
                    logger.info(f"üîç Link para atos concess√≥rios encontrado: {link_atos_suspensao}")
                
                response_atos = token_manager.request("GET", link_atos_suspensao, headers=token_manager.obter_headers(), timeout=DEFAULT_HTTP_TIMEOUT_SEC)
                if response_atos.status_code == 200:
                    atos_concessorios = response_atos.json()
                    if atos_concessorios and len(atos_concessorios) > 0:
                        if debug_mode:
                            logger.info(f"‚úÖ {len(atos_concessorios)} atos concess√≥rios obtidos")
                    else:
                        if debug_mode:
                            logger.info(f"‚ö†Ô∏è  Nenhum ato concess√≥rio de suspens√£o encontrado")
                        atos_concessorios = None
                else:
                    if debug_mode:
                        logger.info(f"‚ö†Ô∏è  Erro {response_atos.status_code} ao consultar atos concess√≥rios")
                    atos_concessorios = None
            except Exception as e:
                if debug_mode:
                    logger.info(f"‚ö†Ô∏è  Erro ao consultar atos concess√≥rios: {str(e)[:50]}")
                atos_concessorios = None
        
        # Usar dados da consulta direta como completos
        dados_completos = dados_due
        
        # OTIMIZA√á√ÉO: Consulta otimizada - apenas 1 requisi√ß√£o ao inv√©s de 2 (ou 3)
        if debug_mode:
            logger.info(f"‚úÖ Consulta direta suficiente - ECONOMIA de 1 requisi√ß√£o HTTP!")
        
        # Resultado b√°sico para due-siscomex.csv
        resultado_basico = {
            'Chave NF': chave_nf,
            'DU-E': numero_due,
            'canal': dados_completos.get('canal', ''),
            'chaveDeAcesso': dados_completos.get('chaveDeAcesso', ''),
            'situacao': dados_completos.get('situacao', ''),
            'valorTotalMercadoria': dados_completos.get('valorTotalMercadoria', '')
        }
        
        # Processar dados completos para normaliza√ß√£o
        if dados_completos and isinstance(dados_completos, dict):
            if debug_mode:
                qtd_itens = len(dados_completos.get('itens', []))
                qtd_eventos = len(dados_completos.get('eventosDoHistorico', []))
                logger.info(f"üìä Processando dados completos - DUE: {numero_due} ({qtd_itens} itens, {qtd_eventos} eventos)")
            
            dados_normalizados = processar_dados_due(dados_completos, atos_concessorios, debug_mode)
            if dados_normalizados:
                resultado_basico['dados_completos'] = dados_normalizados
                if debug_mode:
                    total_registros = sum(len(dados) for dados in dados_normalizados.values())
                    logger.info(f"‚úÖ Dados normalizados: {total_registros} registros totais para DUE: {numero_due}")
            else:
                if debug_mode:
                    logger.info(f"‚ö†Ô∏è  Falha ao processar dados normalizados para DUE: {numero_due}")
        else:
            if debug_mode:
                logger.info(f"‚ö†Ô∏è  Dados completos inv√°lidos ou ausentes para DUE: {numero_due}")
        
        return resultado_basico
        
    except requests.exceptions.Timeout:
        return None  # Timeout silencioso para n√£o poluir logs
    except requests.exceptions.HTTPError as e:
        if e.response.status_code == 404:
            return None  # DU-E n√£o encontrada
        else:
            return None  # Outros erros HTTP
    except Exception:
        return None  # Erro gen√©rico

def processar_chave_individual(args: tuple) -> dict[str, Any] | None:
    """Processa uma √∫nica chave NF - fun√ß√£o para ThreadPoolExecutor COM CACHE TRIPLO"""
    chave_nf, debug_mode, cache_nf_due, cache_chaves_nf, cache_dues, cache_lock = args
    
    if debug_mode:
        logger.info(f"üîç [THREAD] Iniciando processamento da chave {chave_nf[:20]}...")
    
    # CACHE PERSISTENTE: Verificar se j√° conhecemos a DUE desta chave NF
    numero_due = None
    with cache_lock:
        if chave_nf in cache_nf_due:
            numero_due = cache_nf_due[chave_nf]
            if debug_mode:
                logger.info(f"üíæ [CACHE-PERSISTENTE] Chave {chave_nf[:20]} ‚Üí DUE {numero_due} (arquivo existente)")
    
    # Se n√£o conhecemos a DUE, fazer primeira consulta para descobrir
    if not numero_due:
        try:
            # Fazer apenas a primeira consulta para obter o n√∫mero da DUE
            url_primeira = f"{URL_DUE_BASE}?nota-fiscal={chave_nf}"
            response1 = token_manager.request("GET", url_primeira, headers=token_manager.obter_headers(), timeout=DEFAULT_HTTP_TIMEOUT_SEC)
            
            if response1.status_code == 401:
                return {"error": "token_expirado", "chave": chave_nf}
            
            if response1.status_code != 200:
                if response1.status_code == 422:
                    # Rate limiting - n√£o √© erro de token
                    if debug_mode:
                        logger.info(f"‚ö†Ô∏è  [THREAD] Rate limiting (422) na consulta da chave {chave_nf[:20]}")
                    return None  # Retornar None para rate limiting, n√£o erro de token
                elif response1.status_code == 401:
                    # Token expirado
                    return {"error": "token_expirado", "chave": chave_nf}
                else:
                    if debug_mode:
                        logger.info(f"‚ö†Ô∏è  [THREAD] Erro {response1.status_code} na consulta da chave {chave_nf[:20]}")
                    return None
            
            dados1 = response1.json()
            if not dados1 or len(dados1) == 0:
                if debug_mode:
                    logger.info(f"‚ö†Ô∏è  [THREAD] Sem DUE encontrada para chave {chave_nf[:20]}")
                return None
            
            # Extrair n√∫mero da DUE da primeira consulta
            numero_due = dados1[0].get('rel', '')
            if not numero_due:
                if debug_mode:
                    logger.info(f"‚ö†Ô∏è  [THREAD] N√∫mero da DUE n√£o encontrado na resposta para {chave_nf[:20]}")
                return None
            
            # Salvar no cache persistente para futuras execu√ß√µes
            with cache_lock:
                cache_nf_due[chave_nf] = numero_due
                if debug_mode:
                    logger.info(f"üíæ [CACHE-PERSISTENTE] Nova rela√ß√£o salva: {chave_nf[:20]} ‚Üí {numero_due}")
                    
        except Exception as e:
            if debug_mode:
                logger.info(f"‚ùå [THREAD] Erro na primeira consulta para {chave_nf[:20]}: {str(e)[:50]}")
            return None
    # Agora temos o numero_due (do cache ou da consulta)
    # CACHE 1: Verificar se a chave NF j√° foi processada
    with cache_lock:
        if chave_nf in cache_chaves_nf:
            if debug_mode:
                logger.info(f"‚úÖ [CACHE-NF] Chave {chave_nf[:20]} j√° processada - reutilizando dados")
            
            return cache_chaves_nf[chave_nf].copy()
    
    # CACHE 2: Verificar se a DUE j√° foi consultada (de outra chave NF)
    with cache_lock:
        if numero_due in cache_dues:
            if debug_mode:
                logger.info(f"‚úÖ [CACHE-DUE] DUE {numero_due} j√° consultada - reutilizando dados")
            
            # Reutilizar dados da DUE, mas ajustar a chave NF
            resultado_due = cache_dues[numero_due].copy()
            resultado_due['Chave NF'] = chave_nf  # Atualizar chave NF
            
            # Salvar no cache de chaves tamb√©m
            cache_chaves_nf[chave_nf] = resultado_due.copy()
            
            return resultado_due
        
    # Se n√£o est√° no cache, fazer consulta completa
    try:
        # OTIMIZA√á√ÉO: Se j√° conhecemos o n√∫mero da DUE, pular primeira consulta
        if numero_due:
            resultado = consultar_due_por_numero(chave_nf, numero_due, debug_mode)
        else:
            resultado = consultar_due_por_nf(chave_nf, debug_mode)
        
        # Se token expirado, retornar marcador especial para reautentica√ß√£o central
        if isinstance(resultado, dict) and resultado.get("error") == "token_expirado":
            return {"error": "token_expirado", "chave": chave_nf}
        
        # Se sucesso, adicionar aos dois caches
        if resultado and isinstance(resultado, dict) and 'DU-E' in resultado:
            with cache_lock:
                # Cache por chave NF
                cache_chaves_nf[chave_nf] = resultado.copy()
                # Cache por n√∫mero DUE
                cache_dues[numero_due] = resultado.copy()
                if debug_mode:
                    logger.info(f"üì¶ [CACHE] Chave {chave_nf[:20]} e DUE {numero_due} adicionadas ao cache")
        
        return resultado
        
    except Exception as e:
        if debug_mode:
            logger.info(f"‚ùå [THREAD] Erro no processamento da chave {chave_nf[:20]}: {str(e)[:50]}")
        return None

def carregar_cache_due_siscomex(arquivo: str = 'dados/due-siscomex.csv') -> dict[str, str]:
    """Carrega cache de chaves NF -> DUE do arquivo due-siscomex.csv existente"""
    cache_nf_due = {}
    
    if not os.path.exists(arquivo):
        logger.info("üìÑ Arquivo due-siscomex.csv n√£o encontrado - processamento completo ser√° necess√°rio")
        return cache_nf_due
    
    try:
        df = pd.read_csv(arquivo, sep=';', encoding='utf-8-sig')
        
        if 'Chave NF' in df.columns and 'DU-E' in df.columns:
            for _, row in df.iterrows():
                chave_nf = str(row['Chave NF']).strip()
                numero_due = str(row['DU-E']).strip()
                if chave_nf and numero_due:
                    cache_nf_due[chave_nf] = numero_due
            
            logger.info(f"üìã Cache carregado: {len(cache_nf_due)} rela√ß√µes Chave NF ‚Üí DUE do arquivo existente")
        else:
            logger.info("‚ö†Ô∏è  Arquivo due-siscomex.csv existe mas n√£o tem as colunas esperadas")
            
    except Exception as e:
        logger.info(f"‚ö†Ô∏è  Erro ao carregar cache do due-siscomex.csv: {e}")
    
    return cache_nf_due

def processar_chaves_nf(
    chaves_nf: list[str],
    client_id: str,
    client_secret: str,
) -> list[dict[str, Any]]:
    """
    Processa todas as chaves de NF com paraleliza√ß√£o otimizada - OTIMIZADO PARA 1 TOKEN APENAS
    
    OTIMIZA√á√ïES IMPLEMENTADAS:
    ‚Ä¢ Uma √∫nica autentica√ß√£o no in√≠cio (evita m√∫ltiplas calls para /autenticar)
    ‚Ä¢ Token compartilhado entre todas as threads via SharedTokenManager singleton  
    ‚Ä¢ Cache persistente de token (60min padr√£o Siscomex, margem 5min)
    ‚Ä¢ Cache persistente de chaves NF ‚Üí DUE (do arquivo due-siscomex.csv)
    ‚Ä¢ Cache de DUEs consultadas para evitar duplica√ß√µes na mesma execu√ß√£o
    ‚Ä¢ Pular primeira consulta quando DUE j√° √© conhecida (50% menos requests)
    ‚Ä¢ Remo√ß√£o de verifica√ß√µes token_valido() nas fun√ß√µes individuais
    ‚Ä¢ Processamento paralelo mais agressivo (at√© 10 workers)
    ‚Ä¢ Tratamento centralizado de tokens expirados (renova√ß√£o √∫nica)
    ‚Ä¢ Rate limiting inteligente e timeouts otimizados
    """
    
    logger.info("üîß Iniciando processamento das chaves...")
    
    # Cache triplo para m√°xima efici√™ncia
    cache_nf_due = carregar_cache_due_siscomex()  # Cache persistente: chave NF ‚Üí n√∫mero DUE
    cache_chaves_nf = {}  # Cache por chave NF (evita duplicatas da mesma chave)
    cache_dues = {}       # Cache por n√∫mero DUE (evita consultas da mesma DUE)
    lock_cache = threading.Lock()
    
    # Configurar credenciais no token manager compartilhado
    logger.info("üîß Configurando credenciais...")
    token_manager.configurar_credenciais(client_id, client_secret)
    
    # AUTENTICA√á√ÉO √öNICA E INICIAL COM CACHE PERSISTENTE
    logger.info("üîß Verificando autentica√ß√£o (cache + nova se necess√°rio)...")
    try:
        # Tentar usar cache primeiro, depois autenticar se necess√°rio
        auth_success = token_manager.autenticar()
        
        if not auth_success:
            logger.info("‚ùå Falha na autentica√ß√£o inicial")
            return [], {}
        
        logger.info(f"‚úÖ Autentica√ß√£o pronta! {token_manager.status_token()}")
        logger.info(f"üöÄ Otimiza√ß√£o ativa: 2 consultas por DUE (ao inv√©s de 3)")
        
    except Exception as e:
        logger.info(f"‚ùå Erro na autentica√ß√£o: {e}")
        return [], {}
    
    resultados = []
    dados_normalizados_consolidados = {
        'due_principal': [],
        'due_eventos_historico': [],
        'due_itens': [],
        'due_item_enquadramentos': [],
        'due_item_paises_destino': [],
        'due_item_tratamentos_administrativos': [],
        'due_item_tratamentos_administrativos_orgaos': [],
        'due_item_notas_remessa': [],
        'due_item_nota_fiscal_exportacao': [],
        'due_item_notas_complementares': [],
        'due_item_atributos': [],
        'due_item_documentos_importacao': [],
        'due_item_documentos_transformacao': [],
        'due_item_calculo_tributario_tratamentos': [],
        'due_item_calculo_tributario_quadros': [],
        'due_situacoes_carga': [],
        'due_solicitacoes': [],
        'due_declaracao_tributaria_compensacoes': [],
        'due_declaracao_tributaria_recolhimentos': [],
        'due_declaracao_tributaria_contestacoes': [],
        'due_atos_concessorios_suspensao': []
    }
    
    # Cache para evitar normalizar a mesma DUE m√∫ltiplas vezes
    dues_normalizadas = set()
    
    total_chaves = len(chaves_nf)
    processados = 0
    sucessos = 0
    tokens_expirados = []
    
    logger.info(f"\nüöÄ Processando {total_chaves} chaves de NF em paralelo...")
    logger.info("=" * 60)
    
    # Configurar n√∫mero de workers (otimizado para performance m√°xima)
    max_workers = min(10, max(3, total_chaves // 30))  # Performance m√°xima
    logger.info(f"üîß Configurando {max_workers} workers para processamento paralelo...")
    
    # Preparar argumentos (debug apenas para as primeiras 3) + caches compartilhados
    args_list = [(chave, i < 3, cache_nf_due, cache_chaves_nf, cache_dues, lock_cache) for i, chave in enumerate(chaves_nf)]
    
    # Processar em lotes paralelos
    logger.info("üîß Iniciando ThreadPoolExecutor...")
    try:
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            logger.info("‚úÖ ThreadPoolExecutor iniciado!")
            
            # Submeter tarefas
            future_to_chave = {
                executor.submit(processar_chave_individual, args): args[0] 
                for args in args_list
            }
            logger.info(f"‚úÖ {len(future_to_chave)} tarefas submetidas!")
            
            # Processar resultados
            for future in as_completed(future_to_chave, timeout=600):  # 10 minutos timeout total
                chave = future_to_chave[future]
                processados += 1
                
                try:
                    resultado = future.result(timeout=60)  # 1 minuto por tarefa
                    
                    # Verificar se token expirou (raro com token √∫nico bem gerenciado)
                    if isinstance(resultado, dict) and resultado.get("error") == "token_expirado":
                        tokens_expirados.append(chave)
                        logger.info(f"[{processados:3d}/{total_chaves}] üîÑ {chave[:20]}... ‚Üí Token expirado (inesperado!)")
                    elif resultado and isinstance(resultado, dict) and 'DU-E' in resultado:
                        # Adicionar resultado b√°sico
                        resultado_basico = {k: v for k, v in resultado.items() if k != 'dados_completos'}
                        resultados.append(resultado_basico)
                        
                        # Consolidar dados normalizados (evitar duplica√ß√£o por DUE)
                        dados_completos = resultado.get('dados_completos')
                        numero_due = resultado.get('DU-E')
                        
                        if dados_completos and numero_due and numero_due not in dues_normalizadas:
                            # Primeira vez que processamos esta DUE - adicionar dados normalizados
                            for tabela, dados in dados_completos.items():
                                dados_normalizados_consolidados[tabela].extend(dados)
                            
                            # Marcar DUE como j√° normalizada
                            dues_normalizadas.add(numero_due)
                        
                        sucessos += 1
                        logger.info(f"[{processados:3d}/{total_chaves}] ‚úÖ {chave[:20]}... ‚Üí DU-E: {resultado['DU-E']} | Canal: {resultado['canal']}")
                    else:
                        logger.info(f"[{processados:3d}/{total_chaves}] ‚ö†Ô∏è  {chave[:20]}... ‚Üí Sem DU-E")
                        
                except Exception as e:
                    logger.info(f"[{processados:3d}/{total_chaves}] ‚ùå {chave[:20]}... ‚Üí Erro: {str(e)[:30]}")
                
                # Progress a cada 50 (menos frequente)
                if processados % 50 == 0:
                    percentual = (processados / total_chaves) * 100
                    logger.info(f"    üí´ {percentual:.1f}% ({sucessos}/{processados}) - {token_manager.status_token()}")
                    
                    # S√≥ mostrar se h√° problemas
                    if len(tokens_expirados) > 0:
                        logger.info(f"         ‚ö†Ô∏è  Tokens expirados: {len(tokens_expirados)}")
                    
    except Exception as e:
        logger.info(f"‚ùå Erro no ThreadPoolExecutor: {e}")
        logger.info("üîÑ Mudando para processamento sequencial com o mesmo token...")
        # Fallback sequencial simplificado com mesmo token
        return processar_sequencial_simples(chaves_nf, dados_normalizados_consolidados)
    
    # Reprocessar tokens expirados se houver (COM AUTENTICA√á√ÉO √öNCIA)
    if tokens_expirados:
        logger.info(f"\nüîÑ Reprocessando {len(tokens_expirados)} chaves com token expirado...")
        logger.info("üîë Realizando nova autentica√ß√£o para tokens expirados...")
        
        # APENAS UMA autentica√ß√£o para todos os tokens expirados
        if token_manager.autenticar():
            logger.info(f"‚úÖ Token renovado! Processando {len(tokens_expirados)} chaves...")
            
            for chave in tokens_expirados:
                resultado = consultar_due_por_nf(chave, False)
                if resultado and isinstance(resultado, dict) and 'DU-E' in resultado:
                    resultado_basico = {k: v for k, v in resultado.items() if k != 'dados_completos'}
                    resultados.append(resultado_basico)
                    
                    dados_completos = resultado.get('dados_completos')
                    if dados_completos:
                        for tabela, dados in dados_completos.items():
                            dados_normalizados_consolidados[tabela].extend(dados)
                    
                    sucessos += 1
                    logger.info(f"    ‚úÖ {chave[:20]}... ‚Üí DU-E: {resultado['DU-E']}")
                time.sleep(0.2)  # Delay reduzido
        else:
            logger.info("‚ùå Falha na renova√ß√£o do token - chaves n√£o reprocessadas")
    
    logger.info("=" * 60)
    logger.info(f"‚úÖ Processamento conclu√≠do: {len(resultados)}/{total_chaves} sucessos")
    
    # Estat√≠sticas dos caches
    chaves_cache_persistente = len([chave for chave in chaves_nf if chave in cache_nf_due])
    logger.info(f"üíæ Cache persistente: {chaves_cache_persistente} rela√ß√µes Chave NF ‚Üí DUE reutilizadas")
    logger.info(f"üì¶ Cache de chaves NF: {len(cache_chaves_nf)} chaves √∫nicas processadas")
    logger.info(f"üì¶ Cache de DUEs: {len(cache_dues)} DUEs √∫nicas consultadas")
    logger.info(f"üìä DUEs normalizadas: {len(dues_normalizadas)} DUEs √∫nicas nos arquivos normalizados")
    
    # Economia de consultas (cache de DUEs + cache persistente)
    total_consultas_evitadas = total_chaves - len(cache_dues)
    if total_consultas_evitadas > 0:
        percentual_economia = (total_consultas_evitadas / total_chaves) * 100
        logger.info(f"üöÄ Economia de consultas: {total_consultas_evitadas} evitadas ({percentual_economia:.1f}%)")
    
    # Economia de primeira consulta (cache persistente)
    if chaves_cache_persistente > 0:
        logger.info(f"‚ö° Economia de primeira consulta: {chaves_cache_persistente} chaves pularam primeira API")
    
    # Economia de normaliza√ß√£o (duplicatas)
    total_normalizacoes_evitadas = len(cache_dues) - len(dues_normalizadas)
    if total_normalizacoes_evitadas > 0:
        logger.info(f"üéØ Economia de normaliza√ß√£o: {total_normalizacoes_evitadas} DUEs n√£o duplicadas nos arquivos")
    
    return resultados, dados_normalizados_consolidados

def processar_sequencial_simples(
    chaves_nf: list[str],
    dados_normalizados_consolidados: dict[str, list[dict[str, Any]]],
) -> list[dict[str, Any]]:
    """Fallback para processamento sequencial quando o paralelo falha"""
    logger.info("üîÑ Executando processamento sequencial como fallback...")
    
    resultados = []
    sucessos = 0
    
    for i, chave in enumerate(chaves_nf, 1):
        logger.info(f"[{i:3d}/{len(chaves_nf)}] üîÑ Processando {chave[:20]}...")
        
        try:
            resultado = consultar_due_por_nf(chave, False)
            
            if resultado and isinstance(resultado, dict) and 'DU-E' in resultado:
                resultado_basico = {k: v for k, v in resultado.items() if k != 'dados_completos'}
                resultados.append(resultado_basico)
                
                dados_completos = resultado.get('dados_completos')
                if dados_completos:
                    for tabela, dados in dados_completos.items():
                        dados_normalizados_consolidados[tabela].extend(dados)
                
                sucessos += 1
                logger.info(f"[{i:3d}/{len(chaves_nf)}] ‚úÖ {chave[:20]}... ‚Üí DU-E: {resultado['DU-E']}")
            else:
                logger.info(f"[{i:3d}/{len(chaves_nf)}] ‚ö†Ô∏è  {chave[:20]}... ‚Üí Sem DU-E")
                
        except Exception as e:
            logger.info(f"[{i:3d}/{len(chaves_nf)}] ‚ùå {chave[:20]}... ‚Üí Erro: {str(e)[:30]}")
        
        time.sleep(0.5)  # Delay no sequencial
    
    return resultados, dados_normalizados_consolidados

def salvar_resultados_normalizados(
    dados_normalizados: dict[str, list[dict[str, Any]]],
    pasta: str = 'dados/due-normalizados',
    modo_incremental: bool = True,
) -> None:
    """
    Salva todos os dados normalizados no PostgreSQL.
    
    Args:
        dados_normalizados: Dicionario com dados por tabela
        pasta: Pasta de destino (ignorado, mantido para compatibilidade)
        modo_incremental: Mantido para compatibilidade (sempre faz upsert no PostgreSQL)
    """
    
    if not USAR_POSTGRESQL:
        # Fallback para CSV (codigo antigo)
        _salvar_resultados_normalizados_csv(dados_normalizados, pasta, modo_incremental)
        return
    
    logger.info(f"\nüíæ Salvando dados normalizados no PostgreSQL...")
    logger.info("-" * 50)
    
    # Conectar ao banco se nao estiver conectado
    if not db_manager.conn:
        if not db_manager.conectar():
            logger.error("[ERRO] Falha ao conectar ao PostgreSQL, tentando CSV como fallback...")
            _salvar_resultados_normalizados_csv(dados_normalizados, pasta, modo_incremental)
            return
    
    # Contar registros por tabela
    total_registros = 0
    tabelas_salvas = 0
    
    for tabela, dados in dados_normalizados.items():
        if dados:
            logger.info(f"   ‚úÖ {tabela} ‚Üí {len(dados)} registros")
            total_registros += len(dados)
            tabelas_salvas += 1
        else:
            logger.info(f"   ‚ö†Ô∏è  {tabela} ‚Üí Sem dados")
    
    # Inserir no banco
    if db_manager.inserir_due_completa(dados_normalizados):
        logger.info("-" * 50)
        logger.info(f"üìä {tabelas_salvas} tabelas salvas, {total_registros} registros no PostgreSQL")
    else:
        logger.error("[ERRO] Falha ao salvar no PostgreSQL")


def _salvar_resultados_normalizados_csv(
    dados_normalizados: dict[str, list[dict[str, Any]]],
    pasta: str = 'dados/due-normalizados',
    modo_incremental: bool = True,
) -> None:
    """
    Salva todos os dados normalizados em CSVs separados (fallback).
    """
    
    # Garantir que a pasta existe
    if not os.path.exists(pasta):
        os.makedirs(pasta)
    
    logger.info(f"\nüíæ Salvando dados normalizados em: {pasta}")
    logger.info("-" * 50)
    
    # Chaves primarias por tabela para evitar duplicatas
    chaves_primarias = {
        'due_principal': ['numero'],
        'due_eventos_historico': ['numero_due', 'data', 'tipoEvento'],
        'due_itens': ['numero_due', 'numeroItem'],
        'due_item_enquadramentos': ['numero_due', 'numeroItem', 'codigo'],
        'due_item_paises_destino': ['numero_due', 'numeroItem', 'codigoPaisDestino'],
        'due_item_tratamentos_administrativos': ['numero_due', 'numeroItem', 'codigoLPCO'],
        'due_item_tratamentos_administrativos_orgaos': ['numero_due', 'numeroItem', 'codigoLPCO', 'codigoOrgao'],
        'due_item_notas_remessa': ['numero_due', 'numeroItem', 'chaveDeAcesso'],
        'due_item_nota_fiscal_exportacao': ['numero_due', 'chaveDeAcesso'],
        'due_item_notas_complementares': ['numero_due', 'numeroItem', 'chaveDeAcesso'],
        'due_item_atributos': ['numero_due', 'numeroItem', 'codigo'],
        'due_item_documentos_importacao': ['numero_due', 'numeroItem', 'numero'],
        'due_item_documentos_transformacao': ['numero_due', 'numeroItem', 'numero'],
        'due_item_calculo_tributario_tratamentos': ['numero_due', 'numeroItem'],
        'due_item_calculo_tributario_quadros': ['numero_due', 'numeroItem', 'codigoQuadro'],
        'due_situacoes_carga': ['numero_due', 'sequencial'],
        'due_solicitacoes': ['numero_due', 'tipoSolicitacao', 'dataSolicitacao'],
        'due_declaracao_tributaria_compensacoes': ['numero_due', 'codigoReceita'],
        'due_declaracao_tributaria_recolhimentos': ['numero_due', 'codigoReceita'],
        'due_declaracao_tributaria_contestacoes': ['numero_due'],
        'due_atos_concessorios_suspensao': ['numero_due', 'numero']
    }
    
    for tabela, dados in dados_normalizados.items():
        arquivo = os.path.join(pasta, f"{tabela}.csv")
        
        if not dados:
            logger.info(f"   ‚ö†Ô∏è  {tabela}.csv ‚Üí Sem dados novos")
            continue
        
        df_novo = pd.DataFrame(dados)
        df_final = df_novo  # Default
        
        # Se modo incremental e arquivo existe, fazer merge
        if modo_incremental and os.path.exists(arquivo):
            try:
                df_existente = pd.read_csv(arquivo, sep=';', encoding='utf-8-sig')
                chaves = chaves_primarias.get(tabela, ['numero_due'])
                chaves_validas = [c for c in chaves if c in df_novo.columns and c in df_existente.columns]
                
                if chaves_validas:
                    df_existente['_chave_temp'] = df_existente[chaves_validas].astype(str).agg('|'.join, axis=1)
                    df_novo['_chave_temp'] = df_novo[chaves_validas].astype(str).agg('|'.join, axis=1)
                    df_existente = df_existente[~df_existente['_chave_temp'].isin(df_novo['_chave_temp'])]
                    df_existente = df_existente.drop(columns=['_chave_temp'])
                    df_novo = df_novo.drop(columns=['_chave_temp'])
                    df_final = pd.concat([df_existente, df_novo], ignore_index=True)
                else:
                    df_final = pd.concat([df_existente, df_novo], ignore_index=True)
                
                logger.info(f"   ‚úÖ {tabela}.csv ‚Üí {len(df_novo)} novos + {len(df_existente)} existentes = {len(df_final)} total")
            except Exception as e:
                logger.info(f"   ‚ö†Ô∏è  {tabela}.csv ‚Üí Erro ao fazer merge: {e}, sobrescrevendo")
                df_final = df_novo
        else:
            logger.info(f"   ‚úÖ {tabela}.csv ‚Üí {len(df_final)} registros")
        
        df_final.to_csv(arquivo, sep=';', index=False, encoding='utf-8-sig')
    
    logger.info("-" * 50)
    logger.info(f"üìä Total de tabelas salvas: {len([t for t, d in dados_normalizados.items() if d])}")


def salvar_resultados(resultados: list[dict[str, Any]], arquivo: str = 'dados/due-siscomex.csv') -> None:
    """Salva os resultados b√°sicos em CSV (compatibilidade)"""
    if not resultados:
        logger.info("‚ö†Ô∏è  Nenhum resultado para salvar")
        return
    
    try:
        # Garantir que a pasta existe
        pasta = os.path.dirname(arquivo)
        if pasta and not os.path.exists(pasta):
            os.makedirs(pasta)
        
        # Criar DataFrame e salvar
        df = pd.DataFrame(resultados)
        df.to_csv(arquivo, sep=';', index=False, encoding='utf-8-sig')
        
        logger.info(f"\nüíæ Dados b√°sicos salvos em: {arquivo}")
        logger.info(f"   Total de registros: {len(df)}")
        logger.info(f"   Colunas: {', '.join(df.columns.tolist())}")
        
    except Exception as e:
        logger.info(f"‚ùå Erro ao salvar CSV: {e}")

def testar_normalizacao_due(
    client_id: str,
    client_secret: str,
    primeira_chave: str | None = None,
) -> None:
    """Testa a normaliza√ß√£o com apenas uma DU-E para debug"""
    
    # Configurar credenciais no token manager compartilhado
    token_manager.configurar_credenciais(client_id, client_secret)
    
    logger.info("üîë Realizando autentica√ß√£o √∫nica para teste...")
    if not token_manager.autenticar():
        logger.info("‚ùå Falha na autentica√ß√£o para teste")
        return
    
    logger.info(f"‚úÖ Token obtido! V√°lido at√©: {token_manager.expiracao.strftime('%H:%M:%S') if token_manager.expiracao else 'N/A'}")
    
    # Usar a primeira chave ou ler do CSV
    if not primeira_chave:
        chaves_nf = ler_chaves_nf()
        if not chaves_nf:
            return
        primeira_chave = chaves_nf[0]
    
    logger.info(f"\nüß™ TESTE DE NORMALIZA√á√ÉO - Chave: {primeira_chave}")
    logger.info("=" * 60)
    
    # Consultar com debug habilitado
    resultado = consultar_due_por_nf(primeira_chave, debug_mode=True)
    
    if resultado and 'dados_completos' in resultado:
        logger.info("\n‚úÖ Teste de normaliza√ß√£o bem-sucedido!")
        dados_normalizados = resultado['dados_completos']
        for tabela, dados in dados_normalizados.items():
            if dados:
                logger.info(f"  ‚Ä¢ {tabela}: {len(dados)} registros")
    else:
        logger.info("\n‚ùå Teste de normaliza√ß√£o falhou!")
        logger.info("   Verifique os logs acima para identificar o problema")

def main() -> None:
    """Fun√ß√£o principal otimizada"""
    logger.info("=" * 70)
    logger.info("CONSULTA DUE SISCOMEX - VERS√ÉO NORMALIZADA COM ALTA PERFORMANCE")
    logger.info("=" * 70)
    logger.info(f"Data/Hora: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
    logger.info("üöÄ Funcionalidades:")
    logger.info("   ‚Ä¢ Processamento paralelo otimizado")
    logger.info("   ‚Ä¢ Consulta de dados completos da DUE (2-3 requisi√ß√µes por NF)")
    logger.info("   ‚Ä¢ Normaliza√ß√£o em m√∫ltiplas tabelas CSV")
    logger.info("   ‚Ä¢ Consulta de atos concess√≥rios de suspens√£o (drawback)")
    logger.info("   ‚Ä¢ Pool de conex√µes HTTP reutiliz√°veis")
    logger.info("   ‚Ä¢ Rate limiting inteligente")
    logger.info("   ‚Ä¢ Modo de teste para debug")
    logger.info("=" * 70)
    
    # Verificar credenciais de autentica√ß√£o
    logger.info("üîß Verificando credenciais...")
    client_id = os.environ.get("SISCOMEX_CLIENT_ID")
    client_secret = os.environ.get("SISCOMEX_CLIENT_SECRET")
    
    if not client_id or not client_secret:
        logger.info("‚ùå Credenciais do Siscomex n√£o encontradas nas vari√°veis de ambiente")
        logger.info("Configure as vari√°veis SISCOMEX_CLIENT_ID e SISCOMEX_CLIENT_SECRET no arquivo .env")
        return
    
    logger.info("‚úÖ Credenciais encontradas!")
    
    # Ler chaves do CSV
    logger.info("üîß Lendo chaves do CSV...")
    chaves_nf = ler_chaves_nf()
    if not chaves_nf:
        logger.info("‚ùå Nenhuma chave encontrada - abortando")
        return
    
    logger.info(f"‚úÖ {len(chaves_nf)} chaves carregadas com sucesso!")
    
    # Op√ß√µes de processamento
    logger.info(f"\nüìã {len(chaves_nf)} chaves de NF encontradas")
    logger.info("üìÅ Ser√° criado:")
    logger.info("   ‚Ä¢ due-siscomex.csv (dados b√°sicos)")
    logger.info("   ‚Ä¢ dados/due-normalizados/ (13 tabelas normalizadas)")
    logger.info("\nOp√ß√µes:")
    logger.info("  1. Processar todas as chaves (PRODU√á√ÉO)")
    logger.info("  2. Testar normaliza√ß√£o com 1 DU-E (DEBUG)")
    logger.info("  3. Cancelar")
    
    escolha = input("Escolha uma op√ß√£o (1-3): ").strip()
    
    if escolha == "2":
        logger.info("üß™ Iniciando teste de normaliza√ß√£o...")
        testar_normalizacao_due(client_id, client_secret)
        return
    elif escolha != "1":
        logger.info("‚ùå Processamento cancelado")
        return
    
    # Processar todas as chaves
    logger.info("üöÄ Iniciando processamento de todas as chaves...")
    resultados, dados_normalizados = processar_chaves_nf(chaves_nf, client_id, client_secret)
    
    # Salvar resultados
    if resultados:
        # Salvar dados b√°sicos (compatibilidade)
        salvar_resultados(resultados)
        
        # Salvar dados normalizados
        salvar_resultados_normalizados(dados_normalizados)
        
        # Estat√≠sticas finais
        logger.info(f"\nüìä ESTAT√çSTICAS FINAIS:")
        logger.info("-" * 50)
        
        # Status final do token
        logger.info(f"üîë Status do token ao final: {token_manager.status_token()}")
        logger.info("")
        
        df_basico = pd.DataFrame(resultados)
        
        # Canais encontrados
        canais = df_basico['canal'].value_counts()
        logger.info("Canais encontrados:")
        for canal, qtd in canais.items():
            logger.info(f"  - {canal}: {qtd} DU-Es")
        
        # Situa√ß√µes
        if 'situacao' in df_basico.columns:
            situacoes = df_basico['situacao'].value_counts()
            logger.info("\nSitua√ß√µes:")
            for situacao, qtd in situacoes.head(3).items():
                logger.info(f"  - {situacao}: {qtd}")
        
        # Valor total
        valor_total = df_basico['valorTotalMercadoria'].sum()
        logger.info(f"\nValor total das mercadorias: R$ {valor_total:,.2f}")
        logger.info(f"Total de DU-Es processadas: {len(df_basico)}")
        
        # Estat√≠sticas dos dados normalizados
        logger.info(f"\nTabelas normalizadas criadas:")
        total_registros_normalizados = 0
        for tabela, dados in dados_normalizados.items():
            if dados:
                logger.info(f"  - {tabela}: {len(dados)} registros")
                total_registros_normalizados += len(dados)
        
        if total_registros_normalizados == 0:
            logger.info("  ‚ö†Ô∏è  NENHUMA tabela normalizada foi criada!")
            logger.info("  üí° Poss√≠veis causas:")
            logger.info("     ‚Ä¢ API n√£o retorna dados completos")
            logger.info("     ‚Ä¢ Estrutura JSON diferente do esperado")
            logger.info("     ‚Ä¢ Problemas na fun√ß√£o de processamento")
        else:
            logger.info(f"  ‚úÖ Total de registros normalizados: {total_registros_normalizados}")
        
        # Estat√≠sticas espec√≠ficas dos atos concess√≥rios
        atos_count = len(dados_normalizados.get('due_atos_concessorios_suspensao', []))
        if atos_count > 0:
            logger.info(f"\nüéØ Atos concess√≥rios de suspens√£o:")
            logger.info(f"  - Total de registros: {atos_count}")
            
            # Analisar por tipo se houver dados
            df_atos = pd.DataFrame(dados_normalizados['due_atos_concessorios_suspensao'])
            if not df_atos.empty and 'tipo_descricao' in df_atos.columns:
                tipos = df_atos['tipo_descricao'].value_counts()
                for tipo, qtd in tipos.items():
                    logger.info(f"  - {tipo}: {qtd} registros")
        
    logger.info("\n" + "=" * 70)
    logger.info("PROCESSAMENTO FINALIZADO")
    logger.info("=" * 70)

if __name__ == "__main__":
    main()
